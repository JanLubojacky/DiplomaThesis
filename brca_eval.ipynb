{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from src.base_classes.omic_data_loader import OmicDataLoader\n",
    "from src.data_managers.concat import CatOmicDataManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrna_loader = OmicDataLoader(\n",
    "    data_dir=\"tcga_brca_data/splits/mrna\",\n",
    ")\n",
    "mirna_loader = OmicDataLoader(\n",
    "    data_dir=\"tcga_brca_data/splits/mirna\",\n",
    ")\n",
    "meth_loader = OmicDataLoader(\n",
    "    data_dir=\"tcga_brca_data/splits/meth\",\n",
    ")\n",
    "cnv_loader = OmicDataLoader(\n",
    "    data_dir=\"tcga_brca_data/splits/cnv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'logs/brca/mrna_mirna_meth_cnv.csv'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "omic_data_loaders = {\n",
    "    \"mrna\": mrna_loader,\n",
    "    \"mirna\": mirna_loader,\n",
    "    \"meth\": meth_loader,\n",
    "    \"cnv\": cnv_loader,\n",
    "}\n",
    "odm = CatOmicDataManager(omic_data_loaders, n_splits=5)\n",
    "\n",
    "save_folder = f\"logs/brca/{'_'.join(omic_data_loaders.keys())}.csv\"\n",
    "save_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((384, 2002), (97, 279))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrna_loader.get_fold(0)[0].shape, mirna_loader.get_fold(0)[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[I 2024-12-29 23:18:51,847] A new study created in memory with name: no-name-5e3ac71a-eca8-42b4-9cae-f0215d06d8c6\n",
      "[I 2024-12-29 23:18:59,039] Trial 0 finished with value: 0.3382851272402505 and parameters: {'n_neighbors': 18}. Best is trial 0 with value: 0.3382851272402505.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best score: 0.338\n",
      "Best model performance:\n",
      "Accuracy: 0.734 ± 0.028\n",
      "F1 Macro: 0.664 ± 0.051\n",
      "F1 Weighted: 0.694 ± 0.042\n",
      "[{'acc': 0.7731958762886598, 'f1_macro': np.float64(0.7506094329623743), 'f1_weighted': np.float64(0.7566824556515278)}, {'acc': 0.7604166666666666, 'f1_macro': np.float64(0.6902908508413095), 'f1_weighted': np.float64(0.7297437845029587)}, {'acc': 0.6979166666666666, 'f1_macro': np.float64(0.6055165009244468), 'f1_weighted': np.float64(0.6446623722154409)}, {'acc': 0.71875, 'f1_macro': np.float64(0.6263231981981981), 'f1_weighted': np.float64(0.6626193157443158)}, {'acc': 0.71875, 'f1_macro': np.float64(0.6492075862927633), 'f1_weighted': np.float64(0.6756489366244621)}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-29 23:19:06,193] Trial 1 finished with value: 0.350655196849891 and parameters: {'n_neighbors': 13}. Best is trial 1 with value: 0.350655196849891.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best score: 0.351\n",
      "Best model performance:\n",
      "Accuracy: 0.740 ± 0.030\n",
      "F1 Macro: 0.674 ± 0.056\n",
      "F1 Weighted: 0.702 ± 0.046\n",
      "[{'acc': 0.7731958762886598, 'f1_macro': np.float64(0.7506094329623743), 'f1_weighted': np.float64(0.7566824556515278)}, {'acc': 0.75, 'f1_macro': np.float64(0.6781385281385282), 'f1_weighted': np.float64(0.7160624098124098)}, {'acc': 0.6875, 'f1_macro': np.float64(0.5890691803037004), 'f1_weighted': np.float64(0.6268242220133667)}, {'acc': 0.7291666666666666, 'f1_macro': np.float64(0.640909090909091), 'f1_weighted': np.float64(0.67870670995671)}, {'acc': 0.7604166666666666, 'f1_macro': np.float64(0.7137205387205388), 'f1_weighted': np.float64(0.7341785914702581)}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-29 23:19:13,242] Trial 2 finished with value: 0.3369395255668921 and parameters: {'n_neighbors': 16}. Best is trial 1 with value: 0.350655196849891.\n",
      "[I 2024-12-29 23:19:20,334] Trial 3 finished with value: 0.34826029410628295 and parameters: {'n_neighbors': 11}. Best is trial 1 with value: 0.350655196849891.\n",
      "[I 2024-12-29 23:19:27,423] Trial 4 finished with value: 0.350655196849891 and parameters: {'n_neighbors': 13}. Best is trial 1 with value: 0.350655196849891.\n",
      "[I 2024-12-29 23:19:34,498] Trial 5 finished with value: 0.3488846973006166 and parameters: {'n_neighbors': 9}. Best is trial 1 with value: 0.350655196849891.\n",
      "[I 2024-12-29 23:19:41,630] Trial 6 finished with value: 0.35998842368202494 and parameters: {'n_neighbors': 4}. Best is trial 6 with value: 0.35998842368202494.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best score: 0.360\n",
      "Best model performance:\n",
      "Accuracy: 0.744 ± 0.025\n",
      "F1 Macro: 0.683 ± 0.044\n",
      "F1 Weighted: 0.708 ± 0.035\n",
      "[{'acc': 0.7835051546391752, 'f1_macro': np.float64(0.7575687507707486), 'f1_weighted': np.float64(0.7660744775119411)}, {'acc': 0.71875, 'f1_macro': np.float64(0.6535231198131813), 'f1_weighted': np.float64(0.6715726790864318)}, {'acc': 0.71875, 'f1_macro': np.float64(0.6500379318394024), 'f1_weighted': np.float64(0.6816828120136944)}, {'acc': 0.7395833333333334, 'f1_macro': np.float64(0.6458754208754209), 'f1_weighted': np.float64(0.6925960998877665)}, {'acc': 0.7604166666666666, 'f1_macro': np.float64(0.7073610213316095), 'f1_weighted': np.float64(0.7299076842275372)}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-29 23:19:48,730] Trial 7 finished with value: 0.3316724978492605 and parameters: {'n_neighbors': 10}. Best is trial 6 with value: 0.35998842368202494.\n",
      "[I 2024-12-29 23:19:55,853] Trial 8 finished with value: 0.33945389663435027 and parameters: {'n_neighbors': 15}. Best is trial 6 with value: 0.35998842368202494.\n",
      "[I 2024-12-29 23:20:02,933] Trial 9 finished with value: 0.34826029410628295 and parameters: {'n_neighbors': 11}. Best is trial 6 with value: 0.35998842368202494.\n",
      "[I 2024-12-29 23:20:09,996] Trial 10 finished with value: 0.3164854997356952 and parameters: {'n_neighbors': 2}. Best is trial 6 with value: 0.35998842368202494.\n",
      "[I 2024-12-29 23:20:17,028] Trial 11 finished with value: 0.38602559562678096 and parameters: {'n_neighbors': 5}. Best is trial 11 with value: 0.38602559562678096.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best score: 0.386\n",
      "Best model performance:\n",
      "Accuracy: 0.753 ± 0.018\n",
      "F1 Macro: 0.707 ± 0.033\n",
      "F1 Weighted: 0.725 ± 0.025\n",
      "[{'acc': 0.7628865979381443, 'f1_macro': np.float64(0.7228316551845964), 'f1_weighted': np.float64(0.7440822265564535)}, {'acc': 0.75, 'f1_macro': np.float64(0.7214898309237932), 'f1_weighted': np.float64(0.7255993220615863)}, {'acc': 0.7291666666666666, 'f1_macro': np.float64(0.6727843225836345), 'f1_weighted': np.float64(0.6956380509992895)}, {'acc': 0.7395833333333334, 'f1_macro': np.float64(0.665266106442577), 'f1_weighted': np.float64(0.701342203548086)}, {'acc': 0.78125, 'f1_macro': np.float64(0.7533500448614019), 'f1_weighted': np.float64(0.7601655182410133)}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-29 23:20:24,091] Trial 12 finished with value: 0.35998842368202494 and parameters: {'n_neighbors': 4}. Best is trial 11 with value: 0.38602559562678096.\n",
      "[I 2024-12-29 23:20:31,173] Trial 13 finished with value: 0.37054920801349045 and parameters: {'n_neighbors': 6}. Best is trial 11 with value: 0.38602559562678096.\n",
      "[I 2024-12-29 23:20:38,247] Trial 14 finished with value: 0.3690100383200547 and parameters: {'n_neighbors': 7}. Best is trial 11 with value: 0.38602559562678096.\n",
      "[I 2024-12-29 23:20:45,313] Trial 15 finished with value: 0.3690100383200547 and parameters: {'n_neighbors': 7}. Best is trial 11 with value: 0.38602559562678096.\n",
      "[I 2024-12-29 23:20:52,396] Trial 16 finished with value: 0.354975624941604 and parameters: {'n_neighbors': 1}. Best is trial 11 with value: 0.38602559562678096.\n",
      "[I 2024-12-29 23:20:59,501] Trial 17 finished with value: 0.37054920801349045 and parameters: {'n_neighbors': 6}. Best is trial 11 with value: 0.38602559562678096.\n",
      "[I 2024-12-29 23:21:06,595] Trial 18 finished with value: 0.35998842368202494 and parameters: {'n_neighbors': 4}. Best is trial 11 with value: 0.38602559562678096.\n",
      "[I 2024-12-29 23:21:13,712] Trial 19 finished with value: 0.3523020940957591 and parameters: {'n_neighbors': 8}. Best is trial 11 with value: 0.38602559562678096.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model performance:\n",
      "Accuracy: 0.753 ± 0.018\n",
      "F1 Macro: 0.707 ± 0.033\n",
      "F1 Weighted: 0.725 ± 0.025\n",
      "Results saved to logs/brca/mrna_mirna_meth_cnv.csv\n"
     ]
    }
   ],
   "source": [
    "from src.evals.knn import KNNEvaluator\n",
    "\n",
    "knn_eval = KNNEvaluator(\n",
    "    data_manager=odm,\n",
    "    n_trials=20,\n",
    "    verbose=True,\n",
    "    params={\"k_lb\": 1, \"k_ub\": 20},\n",
    ")\n",
    "_ = knn_eval.evaluate()\n",
    "knn_eval.print_best_results()\n",
    "knn_eval.save_results(results_file=save_folder, row_name=\"KNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-29 23:24:10,031] A new study created in memory with name: no-name-cf92ee9b-9d09-4637-98f3-df049596c5e3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-29 23:24:54,765] Trial 0 finished with value: 0.654422484074364 and parameters: {'C': 0.014506386870282696, 'class_weight': None, 'rfe_step': 0.08645655739699043, 'rfe_n_features': 1018}. Best is trial 0 with value: 0.654422484074364.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best score: 0.654\n",
      "Best model performance:\n",
      "Accuracy: 0.869 ± 0.029\n",
      "F1 Macro: 0.867 ± 0.025\n",
      "F1 Weighted: 0.868 ± 0.030\n",
      "[{'acc': 0.8350515463917526, 'f1_macro': np.float64(0.8423874175016907), 'f1_weighted': np.float64(0.8331755220374959)}, {'acc': 0.8854166666666666, 'f1_macro': np.float64(0.8809889050290524), 'f1_weighted': np.float64(0.8847301444683763)}, {'acc': 0.8645833333333334, 'f1_macro': np.float64(0.8601358820951819), 'f1_weighted': np.float64(0.8631617491925928)}, {'acc': 0.84375, 'f1_macro': np.float64(0.8437500000000001), 'f1_weighted': np.float64(0.8430555555555556)}, {'acc': 0.9166666666666666, 'f1_macro': np.float64(0.9096645021645021), 'f1_weighted': np.float64(0.916475018037518)}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-29 23:26:17,070] Trial 1 finished with value: 0.6631012382163934 and parameters: {'C': 0.03144199274661162, 'class_weight': None, 'rfe_step': 0.06124028735449054, 'rfe_n_features': 929}. Best is trial 1 with value: 0.6631012382163934.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best score: 0.663\n",
      "Best model performance:\n",
      "Accuracy: 0.873 ± 0.020\n",
      "F1 Macro: 0.870 ± 0.017\n",
      "F1 Weighted: 0.873 ± 0.020\n",
      "[{'acc': 0.8556701030927835, 'f1_macro': np.float64(0.8584604979827268), 'f1_weighted': np.float64(0.8540038882886761)}, {'acc': 0.8854166666666666, 'f1_macro': np.float64(0.890448461049384), 'f1_weighted': np.float64(0.8862489430463197)}, {'acc': 0.8645833333333334, 'f1_macro': np.float64(0.8504641192141191), 'f1_weighted': np.float64(0.8635718448218448)}, {'acc': 0.8541666666666666, 'f1_macro': np.float64(0.8604701712145533), 'f1_weighted': np.float64(0.8540663456393794)}, {'acc': 0.90625, 'f1_macro': np.float64(0.8910650623885918), 'f1_weighted': np.float64(0.9054339349376113)}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "[I 2024-12-29 23:27:17,784] Trial 2 finished with value: 0.6074111033920482 and parameters: {'C': 0.3577887204349134, 'class_weight': None, 'rfe_step': 0.1761397959335786, 'rfe_n_features': 622}. Best is trial 1 with value: 0.6631012382163934.\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "[I 2024-12-29 23:29:15,446] Trial 3 finished with value: 0.644576407533046 and parameters: {'C': 0.25121833954325606, 'class_weight': 'balanced', 'rfe_step': 0.0734547215609043, 'rfe_n_features': 1755}. Best is trial 1 with value: 0.6631012382163934.\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "[I 2024-12-29 23:30:22,277] Trial 4 finished with value: 0.6359658258101792 and parameters: {'C': 0.11646954401873746, 'class_weight': 'balanced', 'rfe_step': 0.131598673496907, 'rfe_n_features': 1040}. Best is trial 1 with value: 0.6631012382163934.\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "[I 2024-12-29 23:31:35,972] Trial 5 finished with value: 0.6314701700477751 and parameters: {'C': 0.1312263947988365, 'class_weight': None, 'rfe_step': 0.12040407769663651, 'rfe_n_features': 1183}. Best is trial 1 with value: 0.6631012382163934.\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "[I 2024-12-29 23:32:38,098] Trial 6 finished with value: 0.6327085635301991 and parameters: {'C': 3.312272508140937, 'class_weight': None, 'rfe_step': 0.18313265567944914, 'rfe_n_features': 1373}. Best is trial 1 with value: 0.6631012382163934.\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "[I 2024-12-29 23:34:05,699] Trial 7 finished with value: 0.624364062070359 and parameters: {'C': 5.10277796734903, 'class_weight': None, 'rfe_step': 0.11649391605636457, 'rfe_n_features': 1783}. Best is trial 1 with value: 0.6631012382163934.\n",
      "[I 2024-12-29 23:34:38,892] Trial 8 finished with value: 0.6484599004161992 and parameters: {'C': 0.01751919335303451, 'class_weight': None, 'rfe_step': 0.1448834514667536, 'rfe_n_features': 508}. Best is trial 1 with value: 0.6631012382163934.\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "[I 2024-12-29 23:35:37,015] Trial 9 finished with value: 0.634835466526141 and parameters: {'C': 0.3809344146965067, 'class_weight': None, 'rfe_step': 0.1904980543854341, 'rfe_n_features': 1078}. Best is trial 1 with value: 0.6631012382163934.\n",
      "[I 2024-12-29 23:37:24,655] Trial 10 finished with value: 0.6445175593910855 and parameters: {'C': 0.04488444309287521, 'class_weight': 'balanced', 'rfe_step': 0.05135359956373366, 'rfe_n_features': 1512}. Best is trial 1 with value: 0.6631012382163934.\n",
      "[I 2024-12-29 23:38:02,632] Trial 11 finished with value: 0.6595848252809204 and parameters: {'C': 0.010302105229139612, 'class_weight': None, 'rfe_step': 0.08475582498593329, 'rfe_n_features': 853}. Best is trial 1 with value: 0.6631012382163934.\n",
      "[I 2024-12-29 23:38:42,593] Trial 12 finished with value: 0.6753115542125372 and parameters: {'C': 0.01167570312997858, 'class_weight': None, 'rfe_step': 0.08707932315557249, 'rfe_n_features': 806}. Best is trial 12 with value: 0.6753115542125372.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best score: 0.675\n",
      "Best model performance:\n",
      "Accuracy: 0.877 ± 0.021\n",
      "F1 Macro: 0.878 ± 0.016\n",
      "F1 Weighted: 0.877 ± 0.021\n",
      "[{'acc': 0.8556701030927835, 'f1_macro': np.float64(0.8601240496198479), 'f1_weighted': np.float64(0.8551511326179957)}, {'acc': 0.8958333333333334, 'f1_macro': np.float64(0.8928210678210678), 'f1_weighted': np.float64(0.8958573833573834)}, {'acc': 0.875, 'f1_macro': np.float64(0.8690118253779244), 'f1_weighted': np.float64(0.8740782244071719)}, {'acc': 0.8541666666666666, 'f1_macro': np.float64(0.8663043478260869), 'f1_weighted': np.float64(0.8526721014492753)}, {'acc': 0.90625, 'f1_macro': np.float64(0.9013327496473564), 'f1_weighted': np.float64(0.9058330090633461)}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-29 23:40:24,945] Trial 13 finished with value: 0.664244630971043 and parameters: {'C': 0.03809224066395983, 'class_weight': None, 'rfe_step': 0.052375953087451604, 'rfe_n_features': 822}. Best is trial 12 with value: 0.6753115542125372.\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/sklearn/svm/_base.py:1235: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "[I 2024-12-29 23:41:46,270] Trial 14 finished with value: 0.649369881144663 and parameters: {'C': 0.08071029222213583, 'class_weight': 'balanced', 'rfe_step': 0.09318816728798604, 'rfe_n_features': 749}. Best is trial 12 with value: 0.6753115542125372.\n"
     ]
    }
   ],
   "source": [
    "from src.evals.svm import SVMEvaluator\n",
    "\n",
    "svm_eval = SVMEvaluator(\n",
    "    data_manager=odm,\n",
    "    n_trials=15,\n",
    "    verbose=True,\n",
    "    params={\n",
    "        \"C_lb\": 0.01,\n",
    "        \"C_ub\": 10,\n",
    "        # \"no_rfe\": True,\n",
    "        \"rfe_step_range\": (0.05, 0.2),\n",
    "        \"rfe_n_features_range\": (500, 2000),\n",
    "    },\n",
    "    mode=\"linear\",\n",
    ")\n",
    "_ = svm_eval.evaluate()\n",
    "svm_eval.save_results(results_file=save_folder, row_name=\"Linear SVM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[I 2024-12-29 23:38:42,593] Trial 12 finished with value: 0.6753115542125372 and parameters: {'C': 0.01167570312997858, 'class_weight': None, 'rfe_step': 0.08707932315557249, 'rfe_n_features': 806}. Best is trial 12 with value: 0.6753115542125372.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-29 23:41:46,333] A new study created in memory with name: no-name-6ef58fbe-a2ae-41aa-9a37-f1fc50505f52\n",
      "[I 2024-12-29 23:42:28,570] Trial 0 finished with value: 0.5463133255993029 and parameters: {'booster': 'dart', 'lambda': 7.529430279065025e-08, 'alpha': 0.007446938460714343, 'max_depth': 9, 'eta': 0.03767850388884331, 'gamma': 5.79415801264657e-07, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 3.632162587952415e-07, 'skip_drop': 3.0054847009043897e-05}. Best is trial 0 with value: 0.5463133255993029.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best score: 0.546\n",
      "Best model performance:\n",
      "Accuracy: 0.823 ± 0.019\n",
      "F1 Macro: 0.809 ± 0.031\n",
      "F1 Weighted: 0.820 ± 0.019\n",
      "[{'acc': 0.8556701030927835, 'f1_macro': np.float64(0.8585511237988017), 'f1_weighted': np.float64(0.8528422743832402)}, {'acc': 0.8020833333333334, 'f1_macro': np.float64(0.783989898989899), 'f1_weighted': np.float64(0.8025420875420876)}, {'acc': 0.8125, 'f1_macro': np.float64(0.7733204392243294), 'f1_weighted': np.float64(0.8058904806616477)}, {'acc': 0.8125, 'f1_macro': np.float64(0.8034117551944376), 'f1_weighted': np.float64(0.8075289029024173)}, {'acc': 0.8333333333333334, 'f1_macro': np.float64(0.8277306279237092), 'f1_weighted': np.float64(0.8307224749032103)}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-29 23:43:12,379] Trial 1 finished with value: 0.36143074635248557 and parameters: {'booster': 'gbtree', 'lambda': 0.0005962720415396345, 'alpha': 2.2434164462077824e-06, 'max_depth': 9, 'eta': 3.7818567118377255e-08, 'gamma': 1.7870992303806822e-08, 'grow_policy': 'lossguide'}. Best is trial 0 with value: 0.5463133255993029.\n",
      "[I 2024-12-29 23:43:39,956] Trial 2 finished with value: 0.4620702450912804 and parameters: {'booster': 'dart', 'lambda': 0.0004127966461503232, 'alpha': 8.286983086415117e-05, 'max_depth': 4, 'eta': 3.7315216333058706e-06, 'gamma': 1.1577280092527905e-07, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'forest', 'rate_drop': 2.205453081090776e-07, 'skip_drop': 5.665607813036775e-08}. Best is trial 0 with value: 0.5463133255993029.\n",
      "[I 2024-12-29 23:44:00,901] Trial 3 finished with value: 0.4697127362021181 and parameters: {'booster': 'dart', 'lambda': 0.0014974913542514273, 'alpha': 0.00017384451286730598, 'max_depth': 3, 'eta': 0.0002521189083894216, 'gamma': 4.613265074727041e-05, 'grow_policy': 'lossguide', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 0.0015281245213963816, 'skip_drop': 1.6304325003151356e-07}. Best is trial 0 with value: 0.5463133255993029.\n",
      "[I 2024-12-29 23:44:08,031] Trial 4 finished with value: 0.5752897282198838 and parameters: {'booster': 'gblinear', 'lambda': 2.2192995247877933e-07, 'alpha': 3.466705711458514e-06}. Best is trial 4 with value: 0.5752897282198838.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best score: 0.575\n",
      "Best model performance:\n",
      "Accuracy: 0.832 ± 0.033\n",
      "F1 Macro: 0.831 ± 0.036\n",
      "F1 Weighted: 0.832 ± 0.032\n",
      "[{'acc': 0.8144329896907216, 'f1_macro': np.float64(0.8334215649124371), 'f1_weighted': np.float64(0.8154649592616177)}, {'acc': 0.8854166666666666, 'f1_macro': np.float64(0.8890501121219206), 'f1_weighted': np.float64(0.8853136142447977)}, {'acc': 0.8020833333333334, 'f1_macro': np.float64(0.785755873340143), 'f1_weighted': np.float64(0.8025789496084439)}, {'acc': 0.8020833333333334, 'f1_macro': np.float64(0.8003235799288431), 'f1_weighted': np.float64(0.8050252014067804)}, {'acc': 0.8541666666666666, 'f1_macro': np.float64(0.8480941468337397), 'f1_weighted': np.float64(0.8521608166540521)}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-29 23:44:15,450] Trial 5 finished with value: 0.6329014781433995 and parameters: {'booster': 'gblinear', 'lambda': 1.5714183132711784e-06, 'alpha': 0.00023101787904710884}. Best is trial 5 with value: 0.6329014781433995.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best score: 0.633\n",
      "Best model performance:\n",
      "Accuracy: 0.859 ± 0.029\n",
      "F1 Macro: 0.858 ± 0.031\n",
      "F1 Weighted: 0.859 ± 0.028\n",
      "[{'acc': 0.8247422680412371, 'f1_macro': np.float64(0.8330106337205728), 'f1_weighted': np.float64(0.8251674647818602)}, {'acc': 0.90625, 'f1_macro': np.float64(0.9150638763410502), 'f1_weighted': np.float64(0.9065694552277432)}, {'acc': 0.8333333333333334, 'f1_macro': np.float64(0.8310682516255135), 'f1_weighted': np.float64(0.8357106053957745)}, {'acc': 0.8645833333333334, 'f1_macro': np.float64(0.8673590003377237), 'f1_weighted': np.float64(0.8635560902848137)}, {'acc': 0.8645833333333334, 'f1_macro': np.float64(0.845169323430193), 'f1_weighted': np.float64(0.862472068993808)}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-29 23:44:55,978] Trial 6 finished with value: 0.411401932626103 and parameters: {'booster': 'dart', 'lambda': 1.3151612468463119e-08, 'alpha': 0.19915220642463827, 'max_depth': 7, 'eta': 1.5288758450893065e-07, 'gamma': 0.10075787698538398, 'grow_policy': 'depthwise', 'sample_type': 'weighted', 'normalize_type': 'tree', 'rate_drop': 1.0367588535795793e-05, 'skip_drop': 0.017255127207400536}. Best is trial 5 with value: 0.6329014781433995.\n",
      "[I 2024-12-29 23:45:11,158] Trial 7 finished with value: 0.501446754613673 and parameters: {'booster': 'gbtree', 'lambda': 8.90489137173049e-08, 'alpha': 1.3688289142170721e-08, 'max_depth': 2, 'eta': 1.017890907792844e-06, 'gamma': 8.071841456164146e-08, 'grow_policy': 'depthwise'}. Best is trial 5 with value: 0.6329014781433995.\n",
      "[I 2024-12-29 23:45:32,423] Trial 8 finished with value: 0.5676625205450628 and parameters: {'booster': 'dart', 'lambda': 0.05252788777407872, 'alpha': 0.0014355960221452426, 'max_depth': 3, 'eta': 0.05105103332970657, 'gamma': 0.985608890255572, 'grow_policy': 'depthwise', 'sample_type': 'uniform', 'normalize_type': 'forest', 'rate_drop': 0.007973616742843085, 'skip_drop': 0.015053471362953055}. Best is trial 5 with value: 0.6329014781433995.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best score: 0.669\n",
      "Best model performance:\n",
      "Accuracy: 0.875 ± 0.024\n",
      "F1 Macro: 0.874 ± 0.019\n",
      "F1 Weighted: 0.875 ± 0.024\n",
      "[{'acc': 0.8350515463917526, 'f1_macro': np.float64(0.8443644124316393), 'f1_weighted': np.float64(0.8345512775556958)}, {'acc': 0.8854166666666666, 'f1_macro': np.float64(0.8923327374872319), 'f1_weighted': np.float64(0.8857855237770967)}, {'acc': 0.8645833333333334, 'f1_macro': np.float64(0.8619202066791628), 'f1_weighted': np.float64(0.8644428531646576)}, {'acc': 0.8854166666666666, 'f1_macro': np.float64(0.8756944444444444), 'f1_weighted': np.float64(0.8842592592592592)}, {'acc': 0.90625, 'f1_macro': np.float64(0.8942099567099567), 'f1_weighted': np.float64(0.9060583513708513)}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-29 23:45:40,256] Trial 9 finished with value: 0.6692074834549241 and parameters: {'booster': 'gblinear', 'lambda': 0.15435334385093433, 'alpha': 4.811033520538582e-07}. Best is trial 9 with value: 0.6692074834549241.\n",
      "[I 2024-12-29 23:45:47,614] Trial 10 finished with value: 0.6734926113910775 and parameters: {'booster': 'gblinear', 'lambda': 0.8582635407864685, 'alpha': 2.0715915839676434e-08}. Best is trial 10 with value: 0.6734926113910775.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best score: 0.673\n",
      "Best model performance:\n",
      "Accuracy: 0.877 ± 0.025\n",
      "F1 Macro: 0.875 ± 0.022\n",
      "F1 Weighted: 0.877 ± 0.026\n",
      "[{'acc': 0.845360824742268, 'f1_macro': np.float64(0.8513655462184874), 'f1_weighted': np.float64(0.8442562592047128)}, {'acc': 0.8958333333333334, 'f1_macro': np.float64(0.8996024070492156), 'f1_weighted': np.float64(0.895604090550899)}, {'acc': 0.8645833333333334, 'f1_macro': np.float64(0.8619202066791628), 'f1_weighted': np.float64(0.8644428531646576)}, {'acc': 0.8645833333333334, 'f1_macro': np.float64(0.8597222222222223), 'f1_weighted': np.float64(0.8636574074074074)}, {'acc': 0.9166666666666666, 'f1_macro': np.float64(0.9044633527392149), 'f1_weighted': np.float64(0.9162219485495348)}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-29 23:45:54,899] Trial 11 finished with value: 0.6734926113910775 and parameters: {'booster': 'gblinear', 'lambda': 0.9216144397996239, 'alpha': 1.4878537714033387e-08}. Best is trial 10 with value: 0.6734926113910775.\n",
      "[I 2024-12-29 23:46:02,181] Trial 12 finished with value: 0.6604622422674776 and parameters: {'booster': 'gblinear', 'lambda': 0.5718276394471156, 'alpha': 1.0273111856388045e-08}. Best is trial 10 with value: 0.6734926113910775.\n",
      "[I 2024-12-29 23:46:09,458] Trial 13 finished with value: 0.6708904755943285 and parameters: {'booster': 'gblinear', 'lambda': 0.014728876280900761, 'alpha': 1.9185075302905508e-07}. Best is trial 10 with value: 0.6734926113910775.\n",
      "[I 2024-12-29 23:46:16,714] Trial 14 finished with value: 0.5440299415633665 and parameters: {'booster': 'gblinear', 'lambda': 1.5367185577714746e-05, 'alpha': 1.219355377506634e-07}. Best is trial 10 with value: 0.6734926113910775.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model performance:\n",
      "Accuracy: 0.877 ± 0.025\n",
      "F1 Macro: 0.875 ± 0.022\n",
      "F1 Weighted: 0.877 ± 0.026\n",
      "Best hyperparameters:\n",
      "{'booster': 'gblinear', 'lambda': 0.8582635407864685, 'alpha': 2.0715915839676434e-08}\n"
     ]
    }
   ],
   "source": [
    "from src.evals.xgboost import XGBoostEvaluator\n",
    "\n",
    "xgb_eval = XGBoostEvaluator(\n",
    "    data_manager=odm,\n",
    "    n_trials=15,\n",
    "    verbose=True,\n",
    ")\n",
    "_ = xgb_eval.evaluate()\n",
    "xgb_eval.print_best_results()\n",
    "xgb_eval.print_best_parameters()\n",
    "xgb_eval.save_results(results_file=save_folder, row_name=\"XGBoost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-29 23:46:19,287] A new study created in memory with name: no-name-5a910c08-3533-449f-8fd7-f92d2328cf34\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:75: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (12) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (13) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (13) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (13) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (13) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "[I 2024-12-29 23:46:35,615] Trial 0 finished with value: 0.4923788791353378 and parameters: {'lr': 0.002302256859242125, 'dropout': 0.30778871821435905}. Best is trial 0 with value: 0.4923788791353378.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best score: 0.492\n",
      "Best model performance:\n",
      "Accuracy: 0.800 ± 0.055\n",
      "F1 Macro: 0.781 ± 0.071\n",
      "F1 Weighted: 0.788 ± 0.075\n",
      "[{'acc': 0.8350515463917526, 'f1_macro': np.float64(0.8311989449177063), 'f1_weighted': np.float64(0.8323151417378364)}, {'acc': 0.71875, 'f1_macro': np.float64(0.67761702842348), 'f1_weighted': np.float64(0.6623727702356734)}, {'acc': 0.8125, 'f1_macro': np.float64(0.8050946874476286), 'f1_weighted': np.float64(0.8189992877492878)}, {'acc': 0.7604166666666666, 'f1_macro': np.float64(0.7210461712774998), 'f1_weighted': np.float64(0.7484585969219147)}, {'acc': 0.875, 'f1_macro': np.float64(0.8711076280041798), 'f1_weighted': np.float64(0.87538096482062)}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (12) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (13) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (13) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (13) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (13) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "[I 2024-12-29 23:46:52,294] Trial 1 finished with value: 0.4066508870460576 and parameters: {'lr': 0.003741622197068687, 'dropout': 0.24873555743877554}. Best is trial 0 with value: 0.4923788791353378.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (12) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (13) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (13) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (13) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (13) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "[I 2024-12-29 23:47:08,831] Trial 2 finished with value: 0.5358973685043303 and parameters: {'lr': 0.0031388393873678826, 'dropout': 0.5155026693350028}. Best is trial 2 with value: 0.5358973685043303.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best score: 0.536\n",
      "Best model performance:\n",
      "Accuracy: 0.819 ± 0.036\n",
      "F1 Macro: 0.806 ± 0.052\n",
      "F1 Weighted: 0.812 ± 0.049\n",
      "[{'acc': 0.8041237113402062, 'f1_macro': np.float64(0.7986456735764111), 'f1_weighted': np.float64(0.8071263211743386)}, {'acc': 0.8645833333333334, 'f1_macro': np.float64(0.8638090999168111), 'f1_weighted': np.float64(0.8612411269541013)}, {'acc': 0.84375, 'f1_macro': np.float64(0.8502886002886002), 'f1_weighted': np.float64(0.8465007215007215)}, {'acc': 0.7604166666666666, 'f1_macro': np.float64(0.7167814347961406), 'f1_weighted': np.float64(0.7201129525884428)}, {'acc': 0.8229166666666666, 'f1_macro': np.float64(0.8002074961080337), 'f1_weighted': np.float64(0.823632598008158)}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (12) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (13) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (13) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (13) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (13) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "[I 2024-12-29 23:47:25,303] Trial 3 finished with value: 0.5724724469754985 and parameters: {'lr': 0.002847203744033349, 'dropout': 0.341740528089289}. Best is trial 3 with value: 0.5724724469754985.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New best score: 0.572\n",
      "Best model performance:\n",
      "Accuracy: 0.836 ± 0.039\n",
      "F1 Macro: 0.825 ± 0.060\n",
      "F1 Weighted: 0.830 ± 0.051\n",
      "[{'acc': 0.8556701030927835, 'f1_macro': np.float64(0.8565538272046407), 'f1_weighted': np.float64(0.852581845782109)}, {'acc': 0.875, 'f1_macro': np.float64(0.8770205960953117), 'f1_weighted': np.float64(0.8758387191866904)}, {'acc': 0.8645833333333334, 'f1_macro': np.float64(0.8664277795375357), 'f1_weighted': np.float64(0.8669953014465209)}, {'acc': 0.7708333333333334, 'f1_macro': np.float64(0.7131505980770687), 'f1_weighted': np.float64(0.7361138515090722)}, {'acc': 0.8125, 'f1_macro': np.float64(0.8121177629242144), 'f1_weighted': np.float64(0.8197570890783257)}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (12) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (13) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (13) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (13) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (13) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "[I 2024-12-29 23:47:41,557] Trial 4 finished with value: 0.5478825855891791 and parameters: {'lr': 0.0002676972396493769, 'dropout': 0.21827358650162967}. Best is trial 3 with value: 0.5724724469754985.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (12) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (13) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (13) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (13) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (13) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "[I 2024-12-29 23:47:57,636] Trial 5 finished with value: 0.3179990781878369 and parameters: {'lr': 0.005474989471758913, 'dropout': 0.5792880649392715}. Best is trial 3 with value: 0.5724724469754985.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (12) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (13) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (13) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (13) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (13) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "[I 2024-12-29 23:48:13,766] Trial 6 finished with value: 0.52995350007352 and parameters: {'lr': 0.006369232222901578, 'dropout': 0.12606051075871236}. Best is trial 3 with value: 0.5724724469754985.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (12) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (13) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (13) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (13) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (13) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "[I 2024-12-29 23:48:29,960] Trial 7 finished with value: 0.5512091123668942 and parameters: {'lr': 0.0009424590797871234, 'dropout': 0.5804184764781566}. Best is trial 3 with value: 0.5724724469754985.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (12) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (13) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (13) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (13) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (13) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "[I 2024-12-29 23:48:45,992] Trial 8 finished with value: 0.5422152132265512 and parameters: {'lr': 0.0005967510677151452, 'dropout': 0.16186334777770753}. Best is trial 3 with value: 0.5724724469754985.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (12) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (13) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (13) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (13) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n",
      "/home/lubojjan/DiplomaThesis2/.venv/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (13) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "[I 2024-12-29 23:49:01,963] Trial 9 finished with value: 0.5720656248038191 and parameters: {'lr': 0.0018146016354582482, 'dropout': 0.506793834863629}. Best is trial 3 with value: 0.5724724469754985.\n"
     ]
    }
   ],
   "source": [
    "from src.evals.mlp import MLPEvaluator\n",
    "\n",
    "mlp_eval = MLPEvaluator(\n",
    "    data_manager=odm,\n",
    "    n_trials=10,\n",
    "    verbose=True,\n",
    "    params={\n",
    "        \"lr_range\": [1e-4, 1e-2],\n",
    "        \"l2_lambda\": 5e-4,\n",
    "        \"dropout_range\": [0.1, 0.6],\n",
    "        \"hidden_channels\": 64,\n",
    "        \"proj_dim\": 64,\n",
    "        \"batch_size\": 32,\n",
    "        \"max_epochs\": 50,\n",
    "    },\n",
    ")\n",
    "_ = mlp_eval.evaluate()\n",
    "mlp_eval.save_results(results_file=save_folder, row_name=\"MLP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model performance:\n",
      "Accuracy: 0.836 ± 0.039\n",
      "F1 Macro: 0.825 ± 0.060\n",
      "F1 Weighted: 0.830 ± 0.051\n",
      "Best hyperparameters:\n",
      "{'lr': 0.002847203744033349, 'dropout': 0.341740528089289}\n"
     ]
    }
   ],
   "source": [
    "mlp_eval.print_best_results()\n",
    "mlp_eval.print_best_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-30 21:07:37,007] A new study created in memory with name: no-name-ac40b016-d471-44f8-9b28-63a290a5ae1b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: attention integrator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  21%|██        | 52/250 [00:03<00:13, 14.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 050:\n",
      "Train Loss: 0.5776, Train Acc: 0.7865, Train F1 Macro: 0.7081, Train F1 Weighted: 0.7699\n",
      "Val Acc: 0.7938, Val F1 Macro: 0.7533, Val F1 Weighted: 0.7882, Val Geometric Mean: 0.7782\n",
      "Test Acc: 0.7938, Test F1 Macro: 0.7533, Test F1 Weighted: 0.7882\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  41%|████      | 102/250 [00:07<00:10, 14.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 100:\n",
      "Train Loss: 0.2661, Train Acc: 0.9141, Train F1 Macro: 0.9188, Train F1 Weighted: 0.9159\n",
      "Val Acc: 0.8144, Val F1 Macro: 0.8173, Val F1 Weighted: 0.8174, Val Geometric Mean: 0.8164\n",
      "Test Acc: 0.8144, Test F1 Macro: 0.8173, Test F1 Weighted: 0.8174\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  61%|██████    | 152/250 [00:10<00:06, 14.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 150:\n",
      "Train Loss: 0.1871, Train Acc: 0.9401, Train F1 Macro: 0.9422, Train F1 Weighted: 0.9402\n",
      "Val Acc: 0.8557, Val F1 Macro: 0.8563, Val F1 Weighted: 0.8519, Val Geometric Mean: 0.8546\n",
      "Test Acc: 0.8557, Test F1 Macro: 0.8563, Test F1 Weighted: 0.8519\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  81%|████████  | 202/250 [00:13<00:03, 13.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 200:\n",
      "Train Loss: 0.1213, Train Acc: 0.9635, Train F1 Macro: 0.9668, Train F1 Weighted: 0.9635\n",
      "Val Acc: 0.8041, Val F1 Macro: 0.8100, Val F1 Weighted: 0.8060, Val Geometric Mean: 0.8067\n",
      "Test Acc: 0.8041, Test F1 Macro: 0.8100, Test F1 Weighted: 0.8060\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 250/250 [00:17<00:00, 14.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 250:\n",
      "Train Loss: 0.0844, Train Acc: 0.9740, Train F1 Macro: 0.9721, Train F1 Weighted: 0.9742\n",
      "Val Acc: 0.8041, Val F1 Macro: 0.8247, Val F1 Weighted: 0.8074, Val Geometric Mean: 0.8120\n",
      "Test Acc: 0.8041, Test F1 Macro: 0.8247, Test F1 Weighted: 0.8074\n",
      "##################################################\n",
      "Using: attention integrator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  21%|██        | 52/250 [00:03<00:13, 14.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 050:\n",
      "Train Loss: 0.5994, Train Acc: 0.8156, Train F1 Macro: 0.7728, Train F1 Weighted: 0.8062\n",
      "Val Acc: 0.8125, Val F1 Macro: 0.7072, Val F1 Weighted: 0.7887, Val Geometric Mean: 0.7681\n",
      "Test Acc: 0.8125, Test F1 Macro: 0.7072, Test F1 Weighted: 0.7887\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  41%|████      | 102/250 [00:06<00:10, 14.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 100:\n",
      "Train Loss: 0.2553, Train Acc: 0.9325, Train F1 Macro: 0.9319, Train F1 Weighted: 0.9321\n",
      "Val Acc: 0.8542, Val F1 Macro: 0.8630, Val F1 Weighted: 0.8561, Val Geometric Mean: 0.8577\n",
      "Test Acc: 0.8542, Test F1 Macro: 0.8630, Test F1 Weighted: 0.8561\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  61%|██████    | 152/250 [00:10<00:06, 15.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 150:\n",
      "Train Loss: 0.1618, Train Acc: 0.9506, Train F1 Macro: 0.9459, Train F1 Weighted: 0.9507\n",
      "Val Acc: 0.8646, Val F1 Macro: 0.8652, Val F1 Weighted: 0.8660, Val Geometric Mean: 0.8652\n",
      "Test Acc: 0.8646, Test F1 Macro: 0.8652, Test F1 Weighted: 0.8660\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  81%|████████  | 202/250 [00:13<00:03, 14.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 200:\n",
      "Train Loss: 0.1074, Train Acc: 0.9714, Train F1 Macro: 0.9746, Train F1 Weighted: 0.9714\n",
      "Val Acc: 0.8646, Val F1 Macro: 0.8795, Val F1 Weighted: 0.8656, Val Geometric Mean: 0.8699\n",
      "Test Acc: 0.8646, Test F1 Macro: 0.8795, Test F1 Weighted: 0.8656\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 250/250 [00:16<00:00, 14.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 250:\n",
      "Train Loss: 0.0969, Train Acc: 0.9662, Train F1 Macro: 0.9656, Train F1 Weighted: 0.9665\n",
      "Val Acc: 0.8646, Val F1 Macro: 0.8736, Val F1 Weighted: 0.8651, Val Geometric Mean: 0.8678\n",
      "Test Acc: 0.8646, Test F1 Macro: 0.8736, Test F1 Weighted: 0.8651\n",
      "##################################################\n",
      "Using: attention integrator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  21%|██        | 52/250 [00:03<00:12, 15.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 050:\n",
      "Train Loss: 0.6234, Train Acc: 0.7922, Train F1 Macro: 0.7210, Train F1 Weighted: 0.7759\n",
      "Val Acc: 0.7708, Val F1 Macro: 0.7335, Val F1 Weighted: 0.7566, Val Geometric Mean: 0.7535\n",
      "Test Acc: 0.7708, Test F1 Macro: 0.7335, Test F1 Weighted: 0.7566\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  41%|████      | 102/250 [00:06<00:08, 16.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 100:\n",
      "Train Loss: 0.2789, Train Acc: 0.9169, Train F1 Macro: 0.9217, Train F1 Weighted: 0.9161\n",
      "Val Acc: 0.8125, Val F1 Macro: 0.8084, Val F1 Weighted: 0.8110, Val Geometric Mean: 0.8106\n",
      "Test Acc: 0.8125, Test F1 Macro: 0.8084, Test F1 Weighted: 0.8110\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  61%|██████    | 152/250 [00:09<00:06, 16.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 150:\n",
      "Train Loss: 0.1550, Train Acc: 0.9584, Train F1 Macro: 0.9498, Train F1 Weighted: 0.9581\n",
      "Val Acc: 0.8125, Val F1 Macro: 0.8180, Val F1 Weighted: 0.8094, Val Geometric Mean: 0.8133\n",
      "Test Acc: 0.8125, Test F1 Macro: 0.8180, Test F1 Weighted: 0.8094\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  81%|████████  | 202/250 [00:12<00:02, 16.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 200:\n",
      "Train Loss: 0.1348, Train Acc: 0.9558, Train F1 Macro: 0.9579, Train F1 Weighted: 0.9559\n",
      "Val Acc: 0.8333, Val F1 Macro: 0.8348, Val F1 Weighted: 0.8313, Val Geometric Mean: 0.8332\n",
      "Test Acc: 0.8333, Test F1 Macro: 0.8348, Test F1 Weighted: 0.8313\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 250/250 [00:15<00:00, 16.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 250:\n",
      "Train Loss: 0.1063, Train Acc: 0.9584, Train F1 Macro: 0.9540, Train F1 Weighted: 0.9582\n",
      "Val Acc: 0.8021, Val F1 Macro: 0.8037, Val F1 Weighted: 0.8006, Val Geometric Mean: 0.8021\n",
      "Test Acc: 0.8021, Test F1 Macro: 0.8037, Test F1 Weighted: 0.8006\n",
      "##################################################\n",
      "Using: attention integrator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  21%|██        | 52/250 [00:03<00:14, 14.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 050:\n",
      "Train Loss: 0.6068, Train Acc: 0.7948, Train F1 Macro: 0.7393, Train F1 Weighted: 0.7819\n",
      "Val Acc: 0.7604, Val F1 Macro: 0.6759, Val F1 Weighted: 0.7265, Val Geometric Mean: 0.7201\n",
      "Test Acc: 0.7604, Test F1 Macro: 0.6759, Test F1 Weighted: 0.7265\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  41%|████      | 102/250 [00:07<00:10, 14.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 100:\n",
      "Train Loss: 0.3206, Train Acc: 0.9065, Train F1 Macro: 0.8850, Train F1 Weighted: 0.9046\n",
      "Val Acc: 0.8750, Val F1 Macro: 0.8600, Val F1 Weighted: 0.8711, Val Geometric Mean: 0.8687\n",
      "Test Acc: 0.8750, Test F1 Macro: 0.8600, Test F1 Weighted: 0.8711\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  61%|██████    | 152/250 [00:10<00:07, 13.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 150:\n",
      "Train Loss: 0.2251, Train Acc: 0.9221, Train F1 Macro: 0.9192, Train F1 Weighted: 0.9217\n",
      "Val Acc: 0.8646, Val F1 Macro: 0.8621, Val F1 Weighted: 0.8593, Val Geometric Mean: 0.8620\n",
      "Test Acc: 0.8646, Test F1 Macro: 0.8621, Test F1 Weighted: 0.8593\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  81%|████████  | 202/250 [00:14<00:03, 14.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 200:\n",
      "Train Loss: 0.1339, Train Acc: 0.9429, Train F1 Macro: 0.9396, Train F1 Weighted: 0.9427\n",
      "Val Acc: 0.8542, Val F1 Macro: 0.8580, Val F1 Weighted: 0.8521, Val Geometric Mean: 0.8548\n",
      "Test Acc: 0.8542, Test F1 Macro: 0.8580, Test F1 Weighted: 0.8521\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 250/250 [00:17<00:00, 14.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 250:\n",
      "Train Loss: 0.1056, Train Acc: 0.9481, Train F1 Macro: 0.9436, Train F1 Weighted: 0.9482\n",
      "Val Acc: 0.8125, Val F1 Macro: 0.7747, Val F1 Weighted: 0.8039, Val Geometric Mean: 0.7969\n",
      "Test Acc: 0.8125, Test F1 Macro: 0.7747, Test F1 Weighted: 0.8039\n",
      "##################################################\n",
      "Using: attention integrator\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  21%|██        | 52/250 [00:03<00:13, 14.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 050:\n",
      "Train Loss: 0.6042, Train Acc: 0.7948, Train F1 Macro: 0.7545, Train F1 Weighted: 0.7871\n",
      "Val Acc: 0.8229, Val F1 Macro: 0.7247, Val F1 Weighted: 0.7994, Val Geometric Mean: 0.7812\n",
      "Test Acc: 0.8229, Test F1 Macro: 0.7247, Test F1 Weighted: 0.7994\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  41%|████      | 102/250 [00:06<00:09, 15.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 100:\n",
      "Train Loss: 0.2383, Train Acc: 0.9273, Train F1 Macro: 0.9257, Train F1 Weighted: 0.9271\n",
      "Val Acc: 0.8750, Val F1 Macro: 0.8537, Val F1 Weighted: 0.8783, Val Geometric Mean: 0.8689\n",
      "Test Acc: 0.8750, Test F1 Macro: 0.8537, Test F1 Weighted: 0.8783\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  61%|██████    | 152/250 [00:09<00:06, 14.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 150:\n",
      "Train Loss: 0.1915, Train Acc: 0.9351, Train F1 Macro: 0.9326, Train F1 Weighted: 0.9348\n",
      "Val Acc: 0.8854, Val F1 Macro: 0.8621, Val F1 Weighted: 0.8863, Val Geometric Mean: 0.8779\n",
      "Test Acc: 0.8854, Test F1 Macro: 0.8621, Test F1 Weighted: 0.8863\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  81%|████████  | 202/250 [00:12<00:03, 15.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 200:\n",
      "Train Loss: 0.1212, Train Acc: 0.9610, Train F1 Macro: 0.9631, Train F1 Weighted: 0.9608\n",
      "Val Acc: 0.8958, Val F1 Macro: 0.8943, Val F1 Weighted: 0.8980, Val Geometric Mean: 0.8960\n",
      "Test Acc: 0.8958, Test F1 Macro: 0.8943, Test F1 Weighted: 0.8980\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 250/250 [00:15<00:00, 15.72it/s]\n",
      "[I 2024-12-30 21:09:12,952] Trial 0 finished with value: 0.7119609133270712 and parameters: {}. Best is trial 0 with value: 0.7119609133270712.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 250:\n",
      "Train Loss: 0.1567, Train Acc: 0.9455, Train F1 Macro: 0.9493, Train F1 Weighted: 0.9456\n",
      "Val Acc: 0.8646, Val F1 Macro: 0.8406, Val F1 Weighted: 0.8617, Val Geometric Mean: 0.8556\n",
      "Test Acc: 0.8646, Test F1 Macro: 0.8406, Test F1 Weighted: 0.8617\n",
      "##################################################\n",
      "New best score: 0.712\n",
      "Best model performance:\n",
      "Accuracy: 0.892 ± 0.027\n",
      "F1 Macro: 0.895 ± 0.025\n",
      "F1 Weighted: 0.892 ± 0.028\n",
      "[{'acc': 0.8762886597938144, 'f1_macro': np.float64(0.8875211744776963), 'f1_weighted': np.float64(0.8739706729845681)}, {'acc': 0.8958333333333334, 'f1_macro': np.float64(0.9027494041538986), 'f1_weighted': np.float64(0.8962021904437635)}, {'acc': 0.8541666666666666, 'f1_macro': np.float64(0.8549215570320381), 'f1_weighted': np.float64(0.8548432879952692)}, {'acc': 0.8958333333333334, 'f1_macro': np.float64(0.8989130434782608), 'f1_weighted': np.float64(0.8943387681159419)}, {'acc': 0.9375, 'f1_macro': np.float64(0.9325850340136055), 'f1_weighted': np.float64(0.9383475056689341)}]\n",
      "Best model performance:\n",
      "Accuracy: 0.892 ± 0.027\n",
      "F1 Macro: 0.895 ± 0.025\n",
      "F1 Weighted: 0.892 ± 0.028\n"
     ]
    }
   ],
   "source": [
    "from src.evals.mogonet import MOGONETEvaluator\n",
    "from src.data_managers.sample_graph import SampleGraphDataManager\n",
    "\n",
    "mogonet_eval = MOGONETEvaluator(\n",
    "    data_manager=SampleGraphDataManager(\n",
    "        omic_data_loaders=omic_data_loaders,\n",
    "        n_splits=5,\n",
    "        params={\n",
    "            \"graph_style\": \"threshold\",\n",
    "            \"self_connections\": True,\n",
    "            \"avg_degree\": 10,\n",
    "            # \"knn\": 1,\n",
    "        },\n",
    "    ),\n",
    "    n_trials=1,\n",
    "    params={\n",
    "        \"encoder_hidden_channels\": {\n",
    "            \"mrna\": 256,\n",
    "            \"mirna\": 64,\n",
    "            \"meth\": 256,\n",
    "            \"cnv\": 256,\n",
    "        },\n",
    "        \"encoder_type\": \"gat\",\n",
    "        \"dropout\": 0.2,\n",
    "        \"integrator_type\": \"attention\",\n",
    "        \"integration_in_dim\": 16,\n",
    "        \"vcdn_hidden_channels\": 16,\n",
    "        \"epochs\": 250,\n",
    "        \"log_interval\": 50,\n",
    "    }\n",
    ")\n",
    "mogonet_eval.in_channels, mogonet_eval.omic_names\n",
    "mogonet_eval.evaluate()\n",
    "mogonet_eval.print_best_results()\n",
    "# mogonet_eval.save_results(results_file=save_folder, row_name=\"MOGONET\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best model performance (attention integrator):\n",
    "Accuracy: 0.894 ± 0.020\n",
    "F1 Macro: 0.896 ± 0.024\n",
    "F1 Weighted: 0.893 ± 0.021\n",
    "\n",
    "# VCDN vs ATTENTION\n",
    "*vcdn*\n",
    "Best model performance:\n",
    "Accuracy: 0.867 ± 0.055\n",
    "F1 Macro: 0.840 ± 0.113\n",
    "F1 Weighted: 0.858 ± 0.070\n",
    "*attention*\n",
    "Best model performance:\n",
    "Accuracy: 0.888 ± 0.013\n",
    "F1 Macro: 0.889 ± 0.015\n",
    "F1 Weighted: 0.888 ± 0.014\n",
    "\n",
    "# threshold vs knn (5)\n",
    "\n",
    "Best model performance: avg deg = 1\n",
    "Accuracy: 0.902 ± 0.017\n",
    "F1 Macro: 0.898 ± 0.021\n",
    "F1 Weighted: 0.902 ± 0.017\n",
    "\n",
    "Best model performance: avg deg = 2\n",
    "Accuracy: 0.898 ± 0.018\n",
    "F1 Macro: 0.901 ± 0.018\n",
    "F1 Weighted: 0.898 ± 0.018\n",
    "\n",
    "Best model performance: avg deg = 3\n",
    "Accuracy: 0.898 ± 0.018\n",
    "F1 Macro: 0.900 ± 0.021\n",
    "F1 Weighted: 0.898 ± 0.018\n",
    "\n",
    "Best model performance: avg deg = 4\n",
    "Accuracy: 0.892 ± 0.014\n",
    "F1 Macro: 0.898 ± 0.012\n",
    "F1 Weighted: 0.892 ± 0.015\n",
    "\n",
    "Best model performance: avg deg = 5\n",
    "Accuracy: 0.900 ± 0.014\n",
    "F1 Macro: 0.901 ± 0.017\n",
    "F1 Weighted: 0.900 ± 0.014\n",
    "\n",
    "Best model performance: avg deg = 6\n",
    "Accuracy: 0.890 ± 0.019\n",
    "F1 Macro: 0.891 ± 0.020\n",
    "F1 Weighted: 0.888 ± 0.020\n",
    "\n",
    "Best model performance: avg deg = 7\n",
    "Accuracy: 0.879 ± 0.011\n",
    "F1 Macro: 0.883 ± 0.011\n",
    "F1 Weighted: 0.879 ± 0.011\n",
    "\n",
    "Best model performance: avg deg = 8\n",
    "Accuracy: 0.888 ± 0.012\n",
    "F1 Macro: 0.893 ± 0.014\n",
    "F1 Weighted: 0.886 ± 0.014\n",
    "\n",
    "Best model performance: avg deg = 9\n",
    "Accuracy: 0.886 ± 0.024\n",
    "F1 Macro: 0.886 ± 0.024\n",
    "F1 Weighted: 0.884 ± 0.026\n",
    "\n",
    "Best model performance: avg deg = 10\n",
    "Accuracy: 0.892 ± 0.027\n",
    "F1 Macro: 0.895 ± 0.025\n",
    "F1 Weighted: 0.892 ± 0.028\n",
    "\n",
    "\n",
    "knn = 1\n",
    "Best model performance:\n",
    "Accuracy: 0.900 ± 0.014\n",
    "F1 Macro: 0.903 ± 0.012\n",
    "F1 Weighted: 0.900 ± 0.014\n",
    "\n",
    "Best model performance: knn = 2\n",
    "Accuracy: 0.867 ± 0.014\n",
    "F1 Macro: 0.868 ± 0.018\n",
    "F1 Weighted: 0.867 ± 0.014\n",
    "\n",
    "Best model performance: knn = 3\n",
    "Accuracy: 0.865 ± 0.009\n",
    "F1 Macro: 0.870 ± 0.009\n",
    "F1 Weighted: 0.865 ± 0.010\n",
    "\n",
    "Best model performance: knn = 4\n",
    "Accuracy: 0.861 ± 0.005\n",
    "F1 Macro: 0.864 ± 0.009\n",
    "F1 Weighted: 0.861 ± 0.006\n",
    "\n",
    "Best model performance: knn = 5\n",
    "Accuracy: 0.861 ± 0.010\n",
    "F1 Macro: 0.867 ± 0.008\n",
    "F1 Weighted: 0.860 ± 0.010\n",
    "\n",
    "Best model performance: knn = 6\n",
    "Accuracy: 0.873 ± 0.023\n",
    "F1 Macro: 0.882 ± 0.019\n",
    "F1 Weighted: 0.873 ± 0.022\n",
    "\n",
    "Best model performance: knn = 7\n",
    "Accuracy: 0.861 ± 0.010\n",
    "F1 Macro: 0.867 ± 0.008\n",
    "F1 Weighted: 0.860 ± 0.010\n",
    "\n",
    "Best model performance: knn = 8\n",
    "Accuracy: 0.852 ± 0.023\n",
    "F1 Macro: 0.848 ± 0.021\n",
    "F1 Weighted: 0.852 ± 0.023\n",
    "\n",
    "Best model performance: knn = 9\n",
    "Accuracy: 0.861 ± 0.029\n",
    "F1 Macro: 0.857 ± 0.029\n",
    "F1 Weighted: 0.860 ± 0.029\n",
    "\n",
    "Best model performance: knn = 10\n",
    "Accuracy: 0.865 ± 0.042\n",
    "F1 Macro: 0.858 ± 0.040\n",
    "F1 Weighted: 0.863 ± 0.042"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mrna': {'ENSG00000181826': 0, 'ENSG00000278588': 0, 'ENSG00000120594': 0, 'ENSG00000121797': 0, 'ENSG00000140398': 0, 'ENSG00000168062': 0, 'ENSG00000174307': 0, 'ENSG00000184897': 0, 'ENSG00000105497': 0, 'ENSG00000113552': 0, 'ENSG00000188536': 0, 'ENSG00000181004': 0, 'ENSG00000143590': 0, 'ENSG00000006534': 0, 'ENSG00000184792': 0, 'ENSG00000114737': 0, 'ENSG00000130518': 0, 'ENSG00000133561': 0, 'ENSG00000179820': 0, 'ENSG00000196329': 0, 'ENSG00000164626': 0, 'ENSG00000206172': 0, 'ENSG00000196866': 0, 'ENSG00000160013': 0, 'ENSG00000164938': 0, 'ENSG00000260729': 0, 'ENSG00000204161': 0, 'ENSG00000062282': 0, 'ENSG00000087903': 0, 'ENSG00000176641': 0, 'ENSG00000136603': 0, 'ENSG00000113369': 0, 'ENSG00000148935': 0, 'ENSG00000153071': 0, 'ENSG00000174130': 0, 'ENSG00000131016': 0, 'ENSG00000144959': 0, 'ENSG00000203883': 0, 'ENSG00000116574': 0, 'ENSG00000078804': 0, 'ENSG00000120217': 0, 'ENSG00000172667': 0, 'ENSG00000161544': 0, 'ENSG00000121966': 0, 'ENSG00000197646': 0, 'ENSG00000271303': 0, 'ENSG00000125846': 0, 'ENSG00000119801': 0, 'ENSG00000179144': 0, 'ENSG00000196549': 0, 'ENSG00000196230': 0, 'ENSG00000184588': 0, 'ENSG00000026103': 0, 'ENSG00000158578': 0, 'ENSG00000130052': 0, 'ENSG00000119686': 0, 'ENSG00000132475': 0, 'ENSG00000172995': 0, 'ENSG00000022567': 0, 'ENSG00000272398': 0, 'ENSG00000228727': 0, 'ENSG00000171680': 0, 'ENSG00000175538': 0, 'ENSG00000178752': 0, 'ENSG00000119508': 0, 'ENSG00000187837': 0, 'ENSG00000185614': 0, 'ENSG00000178573': 0, 'ENSG00000177191': 0, 'ENSG00000073737': 0, 'ENSG00000092295': 0, 'ENSG00000138623': 0, 'ENSG00000135926': 0, 'ENSG00000185669': 0, 'ENSG00000189283': 0, 'ENSG00000026025': 0, 'ENSG00000168298': 0, 'ENSG00000164330': 0, 'ENSG00000081320': 0, 'ENSG00000174944': 0, 'ENSG00000175449': 0, 'ENSG00000181790': 0, 'ENSG00000260314': 0, 'ENSG00000177455': 0, 'ENSG00000142961': 0, 'ENSG00000073754': 0, 'ENSG00000124575': 0, 'ENSG00000109321': 0, 'ENSG00000175097': 0, 'ENSG00000127364': 0, 'ENSG00000155659': 0, 'ENSG00000110777': 0, 'ENSG00000185730': 0, 'ENSG00000244734': 0, 'ENSG00000196092': 0, 'ENSG00000185304': 0, 'ENSG00000130021': 0, 'ENSG00000182584': 0, 'ENSG00000196517': 0, 'ENSG00000284931': 0, 'ENSG00000084764': 0, 'ENSG00000128322': 0, 'ENSG00000068976': 0, 'ENSG00000166349': 0, 'ENSG00000146592': 0, 'ENSG00000005238': 0, 'ENSG00000111424': 0, 'ENSG00000116096': 0, 'ENSG00000065534': 0, 'ENSG00000181444': 0, 'ENSG00000130787': 0, 'ENSG00000137310': 0, 'ENSG00000159958': 0, 'ENSG00000155090': 0, 'ENSG00000263155': 0, 'ENSG00000166289': 0, 'ENSG00000176845': 0, 'ENSG00000121858': 0, 'ENSG00000136541': 0, 'ENSG00000144749': 0, 'ENSG00000158373': 0, 'ENSG00000163491': 0, 'ENSG00000165272': 0, 'ENSG00000004939': 0, 'ENSG00000171729': 0, 'ENSG00000161835': 0, 'ENSG00000137834': 0, 'ENSG00000129116': 0, 'ENSG00000105369': 0, 'ENSG00000127366': 0, 'ENSG00000174600': 0, 'ENSG00000204186': 0, 'ENSG00000180155': 0, 'ENSG00000131080': 0, 'ENSG00000139174': 0, 'ENSG00000168785': 0, 'ENSG00000105409': 0, 'ENSG00000176125': 0, 'ENSG00000007312': 0, 'ENSG00000171115': 0, 'ENSG00000107796': 0, 'ENSG00000196628': 0, 'ENSG00000151491': 0, 'ENSG00000102554': 0, 'ENSG00000196565': 0, 'ENSG00000132334': 0, 'ENSG00000120318': 0, 'ENSG00000120889': 0, 'ENSG00000124882': 0, 'ENSG00000188153': 0, 'ENSG00000198805': 0, 'ENSG00000185745': 0, 'ENSG00000127362': 0, 'ENSG00000147454': 0, 'ENSG00000137193': 0, 'ENSG00000180061': 0, 'ENSG00000075213': 0, 'ENSG00000169575': 0, 'ENSG00000258674': 0, 'ENSG00000213934': 0, 'ENSG00000135898': 0, 'ENSG00000101276': 0, 'ENSG00000065833': 0, 'ENSG00000180340': 0, 'ENSG00000128274': 0, 'ENSG00000171621': 0, 'ENSG00000080823': 0, 'ENSG00000185090': 0, 'ENSG00000077044': 0, 'ENSG00000090776': 0, 'ENSG00000171860': 0, 'ENSG00000161513': 0, 'ENSG00000054654': 0, 'ENSG00000158555': 0, 'ENSG00000138795': 0, 'ENSG00000160321': 0, 'ENSG00000179163': 0, 'ENSG00000169242': 0, 'ENSG00000099377': 0, 'ENSG00000170412': 0, 'ENSG00000112182': 0, 'ENSG00000170180': 0, 'ENSG00000108219': 0, 'ENSG00000159899': 0, 'ENSG00000154640': 0, 'ENSG00000185015': 0, 'ENSG00000076864': 0, 'ENSG00000171208': 0, 'ENSG00000173369': 0, 'ENSG00000143147': 0, 'ENSG00000165323': 0, 'ENSG00000087589': 0, 'ENSG00000080819': 0, 'ENSG00000214940': 0, 'ENSG00000168671': 0, 'ENSG00000250722': 0, 'ENSG00000165886': 0, 'ENSG00000088899': 0, 'ENSG00000130821': 0, 'ENSG00000172159': 0}, 'mirna': {'ENSG00000221771': 0, 'ENSG00000277402': 0, 'ENSG00000264781': 0, 'ENSG00000274034': 0, 'ENSG00000207975': 0, 'ENSG00000275458': 0, 'ENSG00000284387': 0, 'ENSG00000208037': 0, 'ENSG00000264773': 0, 'ENSG00000276961': 0, 'ENSG00000207808': 0, 'ENSG00000265612': 0, 'ENSG00000274494': 0, 'ENSG00000274552': 0, 'ENSG00000284375': 0, 'ENSG00000263413': 0, 'ENSG00000283929': 0, 'ENSG00000207980': 0, 'ENSG00000266751': 0, 'ENSG00000221445': 0, 'ENSG00000266643': 0, 'ENSG00000264354': 0, 'ENSG00000199090': 0, 'ENSG00000207622': 0, 'ENSG00000263790': 0, 'ENSG00000283200': 0, 'ENSG00000265321': 0, 'ENSG00000221680': 0, 'ENSG00000277942': 0, 'ENSG00000208023': 0, 'ENSG00000265134': 0, 'ENSG00000266017': 0, 'ENSG00000263409': 0, 'ENSG00000275022': 0, 'ENSG00000266594': 0, 'ENSG00000275967': 0, 'ENSG00000274620': 0, 'ENSG00000266325': 0, 'ENSG00000283172': 0, 'ENSG00000264357': 0, 'ENSG00000264102': 0, 'ENSG00000284031': 0, 'ENSG00000207983': 0, 'ENSG00000275101': 0, 'ENSG00000221091': 0, 'ENSG00000264500': 0, 'ENSG00000273776': 0, 'ENSG00000275789': 0, 'ENSG00000266297': 0, 'ENSG00000207776': 0, 'ENSG00000265879': 0, 'ENSG00000274060': 0, 'ENSG00000263857': 0, 'ENSG00000265623': 0, 'ENSG00000264160': 0, 'ENSG00000198974': 0, 'ENSG00000271886': 0, 'ENSG00000267959': 0, 'ENSG00000221063': 0, 'ENSG00000274822': 0, 'ENSG00000275692': 0, 'ENSG00000284229': 0, 'ENSG00000266698': 0, 'ENSG00000266124': 0, 'ENSG00000207650': 0, 'ENSG00000207815': 0, 'ENSG00000276869': 0, 'ENSG00000278420': 0, 'ENSG00000274986': 0, 'ENSG00000274380': 0, 'ENSG00000265333': 0, 'ENSG00000221176': 0, 'ENSG00000264572': 0, 'ENSG00000221603': 0, 'ENSG00000264610': 0, 'ENSG00000207839': 0, 'ENSG00000276926': 0, 'ENSG00000264292': 0, 'ENSG00000265657': 0, 'ENSG00000264864': 0, 'ENSG00000221190': 0, 'ENSG00000276908': 0, 'ENSG00000221214': 0, 'ENSG00000266407': 0, 'ENSG00000266320': 0, 'ENSG00000263527': 0, 'ENSG00000221792': 0, 'ENSG00000221411': 0, 'ENSG00000264796': 0, 'ENSG00000199161': 0, 'ENSG00000266619': 0, 'ENSG00000264947': 0, 'ENSG00000266235': 0, 'ENSG00000207988': 0, 'ENSG00000266533': 0, 'ENSG00000221333': 0, 'ENSG00000284378': 0, 'ENSG00000264585': 0, 'ENSG00000207654': 0, 'ENSG00000274314': 0, 'ENSG00000276753': 0, 'ENSG00000265867': 0, 'ENSG00000264931': 0, 'ENSG00000265137': 0, 'ENSG00000211575': 0, 'ENSG00000275207': 0, 'ENSG00000266139': 0, 'ENSG00000263584': 0, 'ENSG00000207741': 0, 'ENSG00000266270': 0, 'ENSG00000264049': 0, 'ENSG00000264616': 0, 'ENSG00000275651': 0, 'ENSG00000275067': 0, 'ENSG00000221533': 0, 'ENSG00000263361': 0, 'ENSG00000265874': 0, 'ENSG00000265102': 0, 'ENSG00000275667': 0, 'ENSG00000278549': 0, 'ENSG00000207583': 0, 'ENSG00000274466': 0, 'ENSG00000263828': 0, 'ENSG00000264814': 0, 'ENSG00000283204': 0, 'ENSG00000265660': 0, 'ENSG00000222071': 0, 'ENSG00000265996': 0, 'ENSG00000273836': 0, 'ENSG00000211513': 0, 'ENSG00000215973': 0, 'ENSG00000221760': 0, 'ENSG00000274417': 0, 'ENSG00000208002': 0, 'ENSG00000266146': 0, 'ENSG00000266245': 0, 'ENSG00000221406': 0, 'ENSG00000283971': 0, 'ENSG00000274111': 0, 'ENSG00000264349': 0, 'ENSG00000266589': 0, 'ENSG00000266758': 0, 'ENSG00000278658': 0, 'ENSG00000276641': 0, 'ENSG00000276102': 0, 'ENSG00000275950': 0, 'ENSG00000274134': 0, 'ENSG00000263439': 0, 'ENSG00000277379': 0, 'ENSG00000266668': 0, 'ENSG00000212017': 0, 'ENSG00000284154': 0, 'ENSG00000273874': 0, 'ENSG00000263381': 0, 'ENSG00000283498': 0, 'ENSG00000207864': 0, 'ENSG00000264201': 0, 'ENSG00000283532': 0, 'ENSG00000275449': 0, 'ENSG00000265539': 0, 'ENSG00000221394': 0, 'ENSG00000212024': 0, 'ENSG00000202566': 0, 'ENSG00000274705': 0, 'ENSG00000278449': 0, 'ENSG00000278349': 0, 'ENSG00000283514': 0, 'ENSG00000207779': 0, 'ENSG00000266618': 0, 'ENSG00000263813': 0, 'ENSG00000221585': 0, 'ENSG00000266063': 0, 'ENSG00000265201': 0, 'ENSG00000265565': 0, 'ENSG00000264536': 0, 'ENSG00000284186': 0, 'ENSG00000283676': 0, 'ENSG00000263675': 0, 'ENSG00000278447': 0, 'ENSG00000284419': 0, 'ENSG00000198995': 0, 'ENSG00000265112': 0, 'ENSG00000199024': 0, 'ENSG00000283441': 0, 'ENSG00000263963': 0, 'ENSG00000265820': 0, 'ENSG00000283206': 0, 'ENSG00000221325': 0, 'ENSG00000264653': 0, 'ENSG00000283429': 0, 'ENSG00000284224': 0, 'ENSG00000265396': 0, 'ENSG00000283475': 0, 'ENSG00000266038': 0, 'ENSG00000207588': 0, 'ENSG00000281842': 0, 'ENSG00000276404': 0, 'ENSG00000207820': 0, 'ENSG00000252695': 0, 'ENSG00000263831': 0}, 'te': {'HERV-Fc1': 0, 'LTR10C': 0, 'L1M3C_5': 0, 'LTR27E': 0, 'L2': 0, 'L1P4b_5end': 0, 'LTR18A': 0, 'MER87': 0, 'MER57E3': 0, 'THER2': 0, 'MLT1K': 0, 'LTR70': 0, 'LTR1F1': 0, 'MER54B': 0, 'LTR28': 0, 'LTR21A': 0, 'MIR3': 0, 'LTR2': 0, 'MER51E': 0, 'LTR27B': 0, 'L1M3D_5': 0, 'HERVE_a': 0, 'LTR34': 0, 'MER57F': 0, 'LTR38C': 0, 'LTR3': 0, 'L1MA9_5': 0, 'L1P4c_5end': 0, 'HARLEQUIN': 0, 'LTR1C1': 0, 'LTR36': 0, 'LTR60B': 0, 'L1ME3C_3end': 0, 'LOR1b_LTR': 0, 'HERVS71': 0, 'LTR1C': 0, 'LTR47A2': 0, 'MER66A': 0, 'LTR16A1': 0, 'LTR24': 0, 'HERVL66I': 0, 'L1ME4': 0, 'MER57E1': 0, 'MER68B': 0, 'MER70A': 0, 'LTR26E': 0, 'LTR57': 0, 'MER61B': 0, 'AluYf5': 0, 'MLT1G3': 0, 'MER9B': 0, 'L1ME5_3end': 0, 'MER66D': 0, 'LTR58': 0, 'LTR25': 0, 'LTR75_1': 0, 'MER65C': 0, 'LTR1B1': 0, 'LTR71A': 0, 'MER83C': 0, 'HERV-K14CI': 0, 'LTR2B': 0, 'MER52A': 0, 'LTR15': 0, 'MER101': 0, 'MER34A': 0, 'SVA_D': 0, 'HERV1_LTRb': 0, 'LTR25-int': 0, 'LTR72': 0, 'MER66B': 0, 'FRAM': 0, 'HERVE': 0, 'LTR53': 0, 'MLT2D': 0, 'LTR2C': 0, 'AluY': 0, 'LTR64': 0, 'LTR1D1': 0, 'LTR38A1': 0, 'L2B': 0, 'MER74A': 0, 'LTR9B': 0, 'LTR24B': 0, 'MER57C1': 0, 'L1ME2': 0, 'LTR9A1': 0, 'LTR14C': 0, 'LTR62': 0, 'LTR44': 0, 'LTR60': 0, 'MER31B': 0, 'LTR77': 0, 'L1PA14_5': 0, 'MER34D': 0, 'MER57B2': 0, 'LTR37B': 0, 'HERV17': 0, 'MER9': 0, 'LTR26': 0, 'LTR1F': 0, 'LTR12E': 0, 'HERVK11DI': 0, 'LTR2752': 0, 'L1PBA1_5': 0, 'MER67C': 0, 'MIRc': 0, 'MER41E': 0, 'PrimLTR79': 0, 'PABL_A': 0, 'LTR46': 0, 'LOR1I': 0, 'LTR12B': 0, 'AluYa1': 0, 'MLT1J': 0, 'L1MC4': 0, 'L1M1B_5': 0, 'LTR40A': 0, 'HERVI': 0, 'MER57D': 0, 'MLT1H': 0, 'MER34-int': 0, 'LTR26B': 0, 'MER34C2': 0, 'MER67A': 0, 'LTR17': 0, 'MER52C': 0, 'L1ME3A': 0, 'AluYd8': 0, 'MER66C': 0, 'HERV-K14I': 0, 'MER21B': 0, 'MLT1_I': 0, 'MER4D_LTR': 0, 'AluYd3': 0, 'LTR51': 0, 'LTR72B': 0, 'MER88': 0, 'LTR59': 0, 'LTR22C0': 0, 'ALU': 0, 'L1PA7_5': 0, 'HERVK': 0, 'L1P4d_5end': 0, 'L1MD2': 0, 'MER50B': 0, 'L1MB4_5': 0, 'HUERS-P1': 0, 'AluJo': 0, 'LTR6A': 0, 'HERVL': 0, 'IN25': 0, 'MER50C': 0, 'MER21C': 0, 'LTR12': 0, 'AluYb3a2': 0, 'MLT1H1': 0, 'MER4CL34': 0, 'MER67D': 0, 'LTR12C': 0, 'LTR71B': 0, 'LTR39': 0, 'LTR41': 0, 'LTR54B': 0, 'L1ME3E_3end': 0, 'FAM': 0, 'LTR7C': 0, 'LTR8B': 0, 'PABL_B': 0, 'L1PA17_5': 0, 'MLT1C1': 0, 'MER57A1': 0, 'L1HS': 0, 'MER51B': 0, 'LTR19A': 0, 'MER41D': 0, 'LTR53B': 0, 'AluJr4': 0, 'HERVH': 0, 'MER68A': 0, 'L1MCA_5': 0, 'LTR1B': 0, 'MER11D': 0, 'LTR48B': 0, 'HERV35I': 0, 'L1PBB_5': 0, 'L1PA13_5': 0, 'ERVL': 0, 'HERVIP10FH': 0, 'LTR9D': 0, 'ERV3-16A3_I': 0, 'LTR13A': 0, 'L1PREC1': 0, 'L1PBA_5': 0, 'MER92B': 0, 'LTR54': 0, 'L1M3DE_5': 0, 'HERV19I': 0, 'LTR40C': 0, 'L1MA8': 0}}\n"
     ]
    }
   ],
   "source": [
    "mogonet_eval.feature_importance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HERV-Fc1',\n",
       " 'LTR10C',\n",
       " 'L1M3C_5',\n",
       " 'LTR27E',\n",
       " 'L2',\n",
       " 'L1P4b_5end',\n",
       " 'LTR18A',\n",
       " 'MER87',\n",
       " 'MER57E3',\n",
       " 'THER2',\n",
       " 'MLT1K',\n",
       " 'LTR70',\n",
       " 'LTR1F1',\n",
       " 'MER54B',\n",
       " 'LTR28',\n",
       " 'LTR21A',\n",
       " 'MIR3',\n",
       " 'LTR2',\n",
       " 'MER51E',\n",
       " 'LTR27B',\n",
       " 'L1M3D_5',\n",
       " 'HERVE_a',\n",
       " 'LTR34',\n",
       " 'MER57F',\n",
       " 'LTR38C',\n",
       " 'LTR3',\n",
       " 'L1MA9_5',\n",
       " 'L1P4c_5end',\n",
       " 'HARLEQUIN',\n",
       " 'LTR1C1',\n",
       " 'LTR36',\n",
       " 'LTR60B',\n",
       " 'L1ME3C_3end',\n",
       " 'LOR1b_LTR',\n",
       " 'HERVS71',\n",
       " 'LTR1C',\n",
       " 'LTR47A2',\n",
       " 'MER66A',\n",
       " 'LTR16A1',\n",
       " 'LTR24',\n",
       " 'HERVL66I',\n",
       " 'L1ME4',\n",
       " 'MER57E1',\n",
       " 'MER68B',\n",
       " 'MER70A',\n",
       " 'LTR26E',\n",
       " 'LTR57',\n",
       " 'MER61B',\n",
       " 'AluYf5',\n",
       " 'MLT1G3',\n",
       " 'MER9B',\n",
       " 'L1ME5_3end',\n",
       " 'MER66D',\n",
       " 'LTR58',\n",
       " 'LTR25',\n",
       " 'LTR75_1',\n",
       " 'MER65C',\n",
       " 'LTR1B1',\n",
       " 'LTR71A',\n",
       " 'MER83C',\n",
       " 'HERV-K14CI',\n",
       " 'LTR2B',\n",
       " 'MER52A',\n",
       " 'LTR15',\n",
       " 'MER101',\n",
       " 'MER34A',\n",
       " 'SVA_D',\n",
       " 'HERV1_LTRb',\n",
       " 'LTR25-int',\n",
       " 'LTR72',\n",
       " 'MER66B',\n",
       " 'FRAM',\n",
       " 'HERVE',\n",
       " 'LTR53',\n",
       " 'MLT2D',\n",
       " 'LTR2C',\n",
       " 'AluY',\n",
       " 'LTR64',\n",
       " 'LTR1D1',\n",
       " 'LTR38A1',\n",
       " 'L2B',\n",
       " 'MER74A',\n",
       " 'LTR9B',\n",
       " 'LTR24B',\n",
       " 'MER57C1',\n",
       " 'L1ME2',\n",
       " 'LTR9A1',\n",
       " 'LTR14C',\n",
       " 'LTR62',\n",
       " 'LTR44',\n",
       " 'LTR60',\n",
       " 'MER31B',\n",
       " 'LTR77',\n",
       " 'L1PA14_5',\n",
       " 'MER34D',\n",
       " 'MER57B2',\n",
       " 'LTR37B',\n",
       " 'HERV17',\n",
       " 'MER9',\n",
       " 'LTR26',\n",
       " 'LTR1F',\n",
       " 'LTR12E',\n",
       " 'HERVK11DI',\n",
       " 'LTR2752',\n",
       " 'L1PBA1_5',\n",
       " 'MER67C',\n",
       " 'MIRc',\n",
       " 'MER41E',\n",
       " 'PrimLTR79',\n",
       " 'PABL_A',\n",
       " 'LTR46',\n",
       " 'LOR1I',\n",
       " 'LTR12B',\n",
       " 'AluYa1',\n",
       " 'MLT1J',\n",
       " 'L1MC4',\n",
       " 'L1M1B_5',\n",
       " 'LTR40A',\n",
       " 'HERVI',\n",
       " 'MER57D',\n",
       " 'MLT1H',\n",
       " 'MER34-int',\n",
       " 'LTR26B',\n",
       " 'MER34C2',\n",
       " 'MER67A',\n",
       " 'LTR17',\n",
       " 'MER52C',\n",
       " 'L1ME3A',\n",
       " 'AluYd8',\n",
       " 'MER66C',\n",
       " 'HERV-K14I',\n",
       " 'MER21B',\n",
       " 'MLT1_I',\n",
       " 'MER4D_LTR',\n",
       " 'AluYd3',\n",
       " 'LTR51',\n",
       " 'LTR72B',\n",
       " 'MER88',\n",
       " 'LTR59',\n",
       " 'LTR22C0',\n",
       " 'ALU',\n",
       " 'L1PA7_5',\n",
       " 'HERVK',\n",
       " 'L1P4d_5end',\n",
       " 'L1MD2',\n",
       " 'MER50B',\n",
       " 'L1MB4_5',\n",
       " 'HUERS-P1',\n",
       " 'AluJo',\n",
       " 'LTR6A',\n",
       " 'HERVL',\n",
       " 'IN25',\n",
       " 'MER50C',\n",
       " 'MER21C',\n",
       " 'LTR12',\n",
       " 'AluYb3a2',\n",
       " 'MLT1H1',\n",
       " 'MER4CL34',\n",
       " 'MER67D',\n",
       " 'LTR12C',\n",
       " 'LTR71B',\n",
       " 'LTR39',\n",
       " 'LTR41',\n",
       " 'LTR54B',\n",
       " 'L1ME3E_3end',\n",
       " 'FAM',\n",
       " 'LTR7C',\n",
       " 'LTR8B',\n",
       " 'PABL_B',\n",
       " 'L1PA17_5',\n",
       " 'MLT1C1',\n",
       " 'MER57A1',\n",
       " 'L1HS',\n",
       " 'MER51B',\n",
       " 'LTR19A',\n",
       " 'MER41D',\n",
       " 'LTR53B',\n",
       " 'AluJr4',\n",
       " 'HERVH',\n",
       " 'MER68A',\n",
       " 'L1MCA_5',\n",
       " 'LTR1B',\n",
       " 'MER11D',\n",
       " 'LTR48B',\n",
       " 'HERV35I',\n",
       " 'L1PBB_5',\n",
       " 'L1PA13_5',\n",
       " 'ERVL',\n",
       " 'HERVIP10FH',\n",
       " 'LTR9D',\n",
       " 'ERV3-16A3_I',\n",
       " 'LTR13A',\n",
       " 'L1PREC1',\n",
       " 'L1PBA_5',\n",
       " 'MER92B',\n",
       " 'LTR54',\n",
       " 'L1M3DE_5',\n",
       " 'HERV19I',\n",
       " 'LTR40C',\n",
       " 'L1MA8']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = mogonet_eval.data_manager.get_split(0)\n",
    "mogonet_eval.data_manager.feature_names\n",
    "# data['mrna']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded response: {}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.gnn_utils.interactions import gene_names_to_ensembl_ids\n",
    "\n",
    "gene_names_to_ensembl_ids(['GSG2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['BRAF', 'BRCA2'])\n"
     ]
    }
   ],
   "source": [
    "import requests, sys\n",
    " \n",
    "server = \"https://rest.ensembl.org\"\n",
    "ext = \"/lookup/symbol/homo_sapiens\"\n",
    "headers={ \"Content-Type\" : \"application/json\", \"Accept\" : \"application/json\"}\n",
    "r = requests.post(server+ext, headers=headers, data='{ \"symbols\" : [\"BRCA2\", \"BRAF\", \"GSG2\"] }')\n",
    " \n",
    "if not r.ok:\n",
    "  r.raise_for_status()\n",
    "  sys.exit()\n",
    " \n",
    "decoded = r.json()\n",
    "print(decoded.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed tcga_brca_data/splits/cnv/train/train_3.csv\n",
      "Processed tcga_brca_data/splits/cnv/train/train_4.csv\n",
      "Processed tcga_brca_data/splits/cnv/train/train_0.csv\n",
      "Processed tcga_brca_data/splits/cnv/train/train_1.csv\n",
      "Processed tcga_brca_data/splits/cnv/train/train_2.csv\n",
      "Processed tcga_brca_data/splits/cnv/test/test_4.csv\n",
      "Processed tcga_brca_data/splits/cnv/test/test_0.csv\n",
      "Processed tcga_brca_data/splits/cnv/test/test_2.csv\n",
      "Processed tcga_brca_data/splits/cnv/test/test_1.csv\n",
      "Processed tcga_brca_data/splits/cnv/test/test_3.csv\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "from pathlib import Path\n",
    "from typing import Dict, Union\n",
    "\n",
    "from src.gnn_utils.interactions import gene_names_to_ensembl_ids\n",
    "\n",
    "meth = pl.read_csv('tcga_brca_data/raw/cnv.csv')\n",
    "genes = meth['gene'].to_list()\n",
    "\n",
    "g2is = gene_names_to_ensembl_ids(genes)\n",
    "\n",
    "def process_gene_expression_files(base_dir: Union[str, Path], gene_id_mapping: Dict[str, str]) -> None:\n",
    "    \"\"\"\n",
    "    Process gene expression CSV files, renaming columns from gene names to Ensembl IDs.\n",
    "    \n",
    "    Args:\n",
    "        base_dir: Base directory containing the CSV files\n",
    "        gene_id_mapping: Dictionary mapping gene names to Ensembl IDs\n",
    "    \"\"\"\n",
    "    base_dir = Path(base_dir)\n",
    "    \n",
    "    # Process train and test directories\n",
    "    for data_dir in ['train', 'test']:\n",
    "        dir_path = base_dir / data_dir\n",
    "        if not dir_path.exists():\n",
    "            print(f\"Directory not found: {dir_path}\")\n",
    "            continue\n",
    "            \n",
    "        # Process each CSV file in the directory\n",
    "        for file_path in dir_path.glob('*.csv'):\n",
    "            # Read CSV and rename columns\n",
    "            df = pl.read_csv(file_path)\n",
    "            df = df.rename(gene_id_mapping, strict=False)\n",
    "            \n",
    "            # Save back to same location\n",
    "            df.write_csv(file_path)\n",
    "            print(f\"Processed {file_path}\")\n",
    "\n",
    "# process_gene_expression_files(\"tcga_brca_data/splits/mrna\", g2is)\n",
    "# process_gene_expression_files(\"tcga_brca_data/splits/meth\", g2is)\n",
    "process_gene_expression_files(\"tcga_brca_data/splits/cnv\", g2is)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- using less features (like 500 per channel) could give better performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "isolated sample nodes, isolated gene nodes, mean degree: \n",
      "tensor(21) tensor(70) tensor(33.3909)\n",
      "isolated sample nodes, isolated gene nodes, mean degree: \n",
      "tensor(18) tensor(0) tensor(13.1642)\n",
      "isolated sample nodes, isolated gene nodes, mean degree: \n",
      "tensor(10) tensor(637) tensor(35.0291)\n",
      "isolated sample nodes, isolated gene nodes, mean degree: \n",
      "tensor(10) tensor(637) tensor(35.0291)\n",
      "isolated sample nodes, isolated gene nodes, mean degree: \n",
      "tensor(21) tensor(70) tensor(33.3909)\n",
      "isolated sample nodes, isolated gene nodes, mean degree: \n",
      "tensor(18) tensor(0) tensor(13.1642)\n",
      "isolated sample nodes, isolated gene nodes, mean degree: \n",
      "tensor(10) tensor(637) tensor(35.0291)\n",
      "isolated sample nodes, isolated gene nodes, mean degree: \n",
      "tensor(10) tensor(637) tensor(35.0291)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-31 00:47:18,987] A new study created in memory with name: no-name-0b67b866-b814-4552-ab27-238e6b0b2932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "isolated sample nodes, isolated gene nodes, mean degree: \n",
      "tensor(21) tensor(70) tensor(33.3909)\n",
      "isolated sample nodes, isolated gene nodes, mean degree: \n",
      "tensor(18) tensor(0) tensor(13.1642)\n",
      "isolated sample nodes, isolated gene nodes, mean degree: \n",
      "tensor(10) tensor(637) tensor(35.0291)\n",
      "isolated sample nodes, isolated gene nodes, mean degree: \n",
      "tensor(10) tensor(637) tensor(35.0291)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:   3%|▎         | 10/300 [00:05<02:44,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 010:\n",
      "Train Loss: 1.2488, Train Acc: 0.4583, Train F1 Macro: 0.1668, Train F1 Weighted: 0.2962\n",
      "Val Acc: 0.4536, Val F1 Macro: 0.1560, Val F1 Weighted: 0.2831, Val Geometric Mean: 0.2716\n",
      "Test Acc: 0.4536, Test F1 Macro: 0.1560, Test F1 Weighted: 0.2831\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:   7%|▋         | 20/300 [00:10<02:40,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 020:\n",
      "Train Loss: 1.1794, Train Acc: 0.4505, Train F1 Macro: 0.1599, Train F1 Weighted: 0.2875\n",
      "Val Acc: 0.4536, Val F1 Macro: 0.1560, Val F1 Weighted: 0.2831, Val Geometric Mean: 0.2716\n",
      "Test Acc: 0.4536, Test F1 Macro: 0.1560, Test F1 Weighted: 0.2831\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  10%|█         | 30/300 [00:16<02:35,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 030:\n",
      "Train Loss: 1.0319, Train Acc: 0.5885, Train F1 Macro: 0.4359, Train F1 Weighted: 0.5382\n",
      "Val Acc: 0.6495, Val F1 Macro: 0.5042, Val F1 Weighted: 0.6002, Val Geometric Mean: 0.5814\n",
      "Test Acc: 0.6495, Test F1 Macro: 0.5042, Test F1 Weighted: 0.6002\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  13%|█▎        | 40/300 [00:21<02:27,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 040:\n",
      "Train Loss: 0.8908, Train Acc: 0.7057, Train F1 Macro: 0.5506, Train F1 Weighted: 0.6527\n",
      "Val Acc: 0.7216, Val F1 Macro: 0.5812, Val F1 Weighted: 0.6738, Val Geometric Mean: 0.6562\n",
      "Test Acc: 0.7216, Test F1 Macro: 0.5812, Test F1 Weighted: 0.6738\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  17%|█▋        | 50/300 [00:26<02:22,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 050:\n",
      "Train Loss: 0.7442, Train Acc: 0.7682, Train F1 Macro: 0.6139, Train F1 Weighted: 0.7224\n",
      "Val Acc: 0.7423, Val F1 Macro: 0.5956, Val F1 Weighted: 0.6987, Val Geometric Mean: 0.6760\n",
      "Test Acc: 0.7423, Test F1 Macro: 0.5956, Test F1 Weighted: 0.6987\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  20%|██        | 60/300 [00:32<02:18,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 060:\n",
      "Train Loss: 0.6583, Train Acc: 0.7656, Train F1 Macro: 0.6301, Train F1 Weighted: 0.7244\n",
      "Val Acc: 0.7216, Val F1 Macro: 0.5853, Val F1 Weighted: 0.6844, Val Geometric Mean: 0.6612\n",
      "Test Acc: 0.7216, Test F1 Macro: 0.5853, Test F1 Weighted: 0.6844\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  23%|██▎       | 70/300 [00:37<02:10,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 070:\n",
      "Train Loss: 0.5276, Train Acc: 0.8177, Train F1 Macro: 0.6891, Train F1 Weighted: 0.7842\n",
      "Val Acc: 0.7629, Val F1 Macro: 0.6920, Val F1 Weighted: 0.7427, Val Geometric Mean: 0.7319\n",
      "Test Acc: 0.7629, Test F1 Macro: 0.6920, Test F1 Weighted: 0.7427\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  27%|██▋       | 80/300 [00:43<02:06,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 080:\n",
      "Train Loss: 0.4303, Train Acc: 0.8698, Train F1 Macro: 0.8227, Train F1 Weighted: 0.8630\n",
      "Val Acc: 0.7629, Val F1 Macro: 0.7151, Val F1 Weighted: 0.7511, Val Geometric Mean: 0.7428\n",
      "Test Acc: 0.7629, Test F1 Macro: 0.7151, Test F1 Weighted: 0.7511\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  30%|███       | 90/300 [00:48<01:59,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 090:\n",
      "Train Loss: 0.3577, Train Acc: 0.9141, Train F1 Macro: 0.8942, Train F1 Weighted: 0.9131\n",
      "Val Acc: 0.7320, Val F1 Macro: 0.7430, Val F1 Weighted: 0.7342, Val Geometric Mean: 0.7364\n",
      "Test Acc: 0.7320, Test F1 Macro: 0.7430, Test F1 Weighted: 0.7342\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  33%|███▎      | 100/300 [00:53<01:54,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 100:\n",
      "Train Loss: 0.2894, Train Acc: 0.9193, Train F1 Macro: 0.8887, Train F1 Weighted: 0.9178\n",
      "Val Acc: 0.8041, Val F1 Macro: 0.7970, Val F1 Weighted: 0.8025, Val Geometric Mean: 0.8012\n",
      "Test Acc: 0.8041, Test F1 Macro: 0.7970, Test F1 Weighted: 0.8025\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  37%|███▋      | 110/300 [00:59<01:48,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 110:\n",
      "Train Loss: 0.2506, Train Acc: 0.9193, Train F1 Macro: 0.9051, Train F1 Weighted: 0.9194\n",
      "Val Acc: 0.7938, Val F1 Macro: 0.7842, Val F1 Weighted: 0.7872, Val Geometric Mean: 0.7884\n",
      "Test Acc: 0.7938, Test F1 Macro: 0.7842, Test F1 Weighted: 0.7872\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  40%|████      | 120/300 [01:04<01:43,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 120:\n",
      "Train Loss: 0.2465, Train Acc: 0.9297, Train F1 Macro: 0.9129, Train F1 Weighted: 0.9274\n",
      "Val Acc: 0.7526, Val F1 Macro: 0.7446, Val F1 Weighted: 0.7455, Val Geometric Mean: 0.7476\n",
      "Test Acc: 0.7526, Test F1 Macro: 0.7446, Test F1 Weighted: 0.7455\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  43%|████▎     | 130/300 [01:10<01:37,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 130:\n",
      "Train Loss: 0.1884, Train Acc: 0.9453, Train F1 Macro: 0.9298, Train F1 Weighted: 0.9449\n",
      "Val Acc: 0.8247, Val F1 Macro: 0.7983, Val F1 Weighted: 0.8248, Val Geometric Mean: 0.8159\n",
      "Test Acc: 0.8247, Test F1 Macro: 0.7983, Test F1 Weighted: 0.8248\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  47%|████▋     | 140/300 [01:15<01:32,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 140:\n",
      "Train Loss: 0.1341, Train Acc: 0.9609, Train F1 Macro: 0.9514, Train F1 Weighted: 0.9605\n",
      "Val Acc: 0.8247, Val F1 Macro: 0.8057, Val F1 Weighted: 0.8215, Val Geometric Mean: 0.8173\n",
      "Test Acc: 0.8247, Test F1 Macro: 0.8057, Test F1 Weighted: 0.8215\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  50%|█████     | 150/300 [01:20<01:25,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 150:\n",
      "Train Loss: 0.1064, Train Acc: 0.9740, Train F1 Macro: 0.9725, Train F1 Weighted: 0.9738\n",
      "Val Acc: 0.8557, Val F1 Macro: 0.8520, Val F1 Weighted: 0.8544, Val Geometric Mean: 0.8540\n",
      "Test Acc: 0.8557, Test F1 Macro: 0.8520, Test F1 Weighted: 0.8544\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  53%|█████▎    | 160/300 [01:26<01:19,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 160:\n",
      "Train Loss: 0.1159, Train Acc: 0.9714, Train F1 Macro: 0.9716, Train F1 Weighted: 0.9713\n",
      "Val Acc: 0.8144, Val F1 Macro: 0.8039, Val F1 Weighted: 0.8160, Val Geometric Mean: 0.8114\n",
      "Test Acc: 0.8144, Test F1 Macro: 0.8039, Test F1 Weighted: 0.8160\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  57%|█████▋    | 170/300 [01:31<01:14,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 170:\n",
      "Train Loss: 0.0858, Train Acc: 0.9792, Train F1 Macro: 0.9740, Train F1 Weighted: 0.9794\n",
      "Val Acc: 0.8351, Val F1 Macro: 0.8498, Val F1 Weighted: 0.8375, Val Geometric Mean: 0.8407\n",
      "Test Acc: 0.8351, Test F1 Macro: 0.8498, Test F1 Weighted: 0.8375\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  60%|██████    | 180/300 [01:37<01:09,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 180:\n",
      "Train Loss: 0.1166, Train Acc: 0.9661, Train F1 Macro: 0.9600, Train F1 Weighted: 0.9659\n",
      "Val Acc: 0.8041, Val F1 Macro: 0.8106, Val F1 Weighted: 0.8066, Val Geometric Mean: 0.8071\n",
      "Test Acc: 0.8041, Test F1 Macro: 0.8106, Test F1 Weighted: 0.8066\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  63%|██████▎   | 190/300 [01:42<01:03,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 190:\n",
      "Train Loss: 0.3800, Train Acc: 0.8490, Train F1 Macro: 0.8557, Train F1 Weighted: 0.8531\n",
      "Val Acc: 0.6804, Val F1 Macro: 0.7117, Val F1 Weighted: 0.6804, Val Geometric Mean: 0.6907\n",
      "Test Acc: 0.6804, Test F1 Macro: 0.7117, Test F1 Weighted: 0.6804\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  67%|██████▋   | 200/300 [01:47<00:56,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 200:\n",
      "Train Loss: 0.1688, Train Acc: 0.9505, Train F1 Macro: 0.9422, Train F1 Weighted: 0.9500\n",
      "Val Acc: 0.8144, Val F1 Macro: 0.8060, Val F1 Weighted: 0.8046, Val Geometric Mean: 0.8083\n",
      "Test Acc: 0.8144, Test F1 Macro: 0.8060, Test F1 Weighted: 0.8046\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  70%|███████   | 210/300 [01:53<00:51,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 210:\n",
      "Train Loss: 0.0881, Train Acc: 0.9766, Train F1 Macro: 0.9771, Train F1 Weighted: 0.9765\n",
      "Val Acc: 0.8454, Val F1 Macro: 0.8552, Val F1 Weighted: 0.8479, Val Geometric Mean: 0.8495\n",
      "Test Acc: 0.8454, Test F1 Macro: 0.8552, Test F1 Weighted: 0.8479\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  73%|███████▎  | 220/300 [01:58<00:45,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 220:\n",
      "Train Loss: 0.0877, Train Acc: 0.9714, Train F1 Macro: 0.9626, Train F1 Weighted: 0.9715\n",
      "Val Acc: 0.7938, Val F1 Macro: 0.8080, Val F1 Weighted: 0.7966, Val Geometric Mean: 0.7995\n",
      "Test Acc: 0.7938, Test F1 Macro: 0.8080, Test F1 Weighted: 0.7966\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  77%|███████▋  | 230/300 [02:04<00:39,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 230:\n",
      "Train Loss: 0.0874, Train Acc: 0.9688, Train F1 Macro: 0.9665, Train F1 Weighted: 0.9687\n",
      "Val Acc: 0.8247, Val F1 Macro: 0.8151, Val F1 Weighted: 0.8224, Val Geometric Mean: 0.8208\n",
      "Test Acc: 0.8247, Test F1 Macro: 0.8151, Test F1 Weighted: 0.8224\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  80%|████████  | 240/300 [02:09<00:34,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 240:\n",
      "Train Loss: 0.0834, Train Acc: 0.9792, Train F1 Macro: 0.9756, Train F1 Weighted: 0.9792\n",
      "Val Acc: 0.7938, Val F1 Macro: 0.8043, Val F1 Weighted: 0.7982, Val Geometric Mean: 0.7988\n",
      "Test Acc: 0.7938, Test F1 Macro: 0.8043, Test F1 Weighted: 0.7982\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  83%|████████▎ | 250/300 [02:14<00:28,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 250:\n",
      "Train Loss: 0.0464, Train Acc: 0.9922, Train F1 Macro: 0.9913, Train F1 Weighted: 0.9922\n",
      "Val Acc: 0.7835, Val F1 Macro: 0.7985, Val F1 Weighted: 0.7881, Val Geometric Mean: 0.7900\n",
      "Test Acc: 0.7835, Test F1 Macro: 0.7985, Test F1 Weighted: 0.7881\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  87%|████████▋ | 260/300 [02:20<00:23,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 260:\n",
      "Train Loss: 0.0612, Train Acc: 0.9870, Train F1 Macro: 0.9868, Train F1 Weighted: 0.9870\n",
      "Val Acc: 0.7938, Val F1 Macro: 0.8084, Val F1 Weighted: 0.7995, Val Geometric Mean: 0.8005\n",
      "Test Acc: 0.7938, Test F1 Macro: 0.8084, Test F1 Weighted: 0.7995\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  90%|█████████ | 270/300 [02:25<00:17,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 270:\n",
      "Train Loss: 0.0690, Train Acc: 0.9818, Train F1 Macro: 0.9802, Train F1 Weighted: 0.9818\n",
      "Val Acc: 0.8351, Val F1 Macro: 0.8487, Val F1 Weighted: 0.8370, Val Geometric Mean: 0.8402\n",
      "Test Acc: 0.8351, Test F1 Macro: 0.8487, Test F1 Weighted: 0.8370\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  93%|█████████▎| 280/300 [02:31<00:11,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 280:\n",
      "Train Loss: 0.0421, Train Acc: 0.9922, Train F1 Macro: 0.9908, Train F1 Weighted: 0.9922\n",
      "Val Acc: 0.7629, Val F1 Macro: 0.7769, Val F1 Weighted: 0.7688, Val Geometric Mean: 0.7695\n",
      "Test Acc: 0.7629, Test F1 Macro: 0.7769, Test F1 Weighted: 0.7688\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  97%|█████████▋| 290/300 [02:36<00:05,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 290:\n",
      "Train Loss: 0.0343, Train Acc: 0.9948, Train F1 Macro: 0.9934, Train F1 Weighted: 0.9948\n",
      "Val Acc: 0.8144, Val F1 Macro: 0.8257, Val F1 Weighted: 0.8180, Val Geometric Mean: 0.8194\n",
      "Test Acc: 0.8144, Test F1 Macro: 0.8257, Test F1 Weighted: 0.8180\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 300/300 [02:41<00:00,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 300:\n",
      "Train Loss: 0.0422, Train Acc: 0.9870, Train F1 Macro: 0.9820, Train F1 Weighted: 0.9870\n",
      "Val Acc: 0.8557, Val F1 Macro: 0.8507, Val F1 Weighted: 0.8570, Val Geometric Mean: 0.8544\n",
      "Test Acc: 0.8557, Test F1 Macro: 0.8507, Test F1 Weighted: 0.8570\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "isolated sample nodes, isolated gene nodes, mean degree: \n",
      "tensor(22) tensor(68) tensor(33.4408)\n",
      "isolated sample nodes, isolated gene nodes, mean degree: \n",
      "tensor(18) tensor(0) tensor(13.1642)\n",
      "isolated sample nodes, isolated gene nodes, mean degree: \n",
      "tensor(8) tensor(642) tensor(35.1705)\n",
      "isolated sample nodes, isolated gene nodes, mean degree: \n",
      "tensor(8) tensor(642) tensor(35.1705)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:   3%|▎         | 10/300 [00:05<02:49,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 010:\n",
      "Train Loss: 1.2505, Train Acc: 0.4338, Train F1 Macro: 0.1602, Train F1 Weighted: 0.2842\n",
      "Val Acc: 0.4583, Val F1 Macro: 0.1571, Val F1 Weighted: 0.2881, Val Geometric Mean: 0.2748\n",
      "Test Acc: 0.4583, Test F1 Macro: 0.1571, Test F1 Weighted: 0.2881\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:   7%|▋         | 20/300 [00:10<02:44,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 020:\n",
      "Train Loss: 1.1117, Train Acc: 0.4519, Train F1 Macro: 0.2238, Train F1 Weighted: 0.3450\n",
      "Val Acc: 0.4792, Val F1 Macro: 0.1979, Val F1 Weighted: 0.3307, Val Geometric Mean: 0.3153\n",
      "Test Acc: 0.4792, Test F1 Macro: 0.1979, Test F1 Weighted: 0.3307\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  10%|█         | 30/300 [00:16<02:37,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 030:\n",
      "Train Loss: 1.0017, Train Acc: 0.5870, Train F1 Macro: 0.4248, Train F1 Weighted: 0.5153\n",
      "Val Acc: 0.7292, Val F1 Macro: 0.5894, Val F1 Weighted: 0.6804, Val Geometric Mean: 0.6637\n",
      "Test Acc: 0.7292, Test F1 Macro: 0.5894, Test F1 Weighted: 0.6804\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  13%|█▎        | 40/300 [00:22<02:31,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 040:\n",
      "Train Loss: 0.8948, Train Acc: 0.6831, Train F1 Macro: 0.5499, Train F1 Weighted: 0.6371\n",
      "Val Acc: 0.7812, Val F1 Macro: 0.6284, Val F1 Weighted: 0.7337, Val Geometric Mean: 0.7115\n",
      "Test Acc: 0.7812, Test F1 Macro: 0.6284, Test F1 Weighted: 0.7337\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  17%|█▋        | 50/300 [00:27<02:25,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 050:\n",
      "Train Loss: 0.8107, Train Acc: 0.7013, Train F1 Macro: 0.5491, Train F1 Weighted: 0.6495\n",
      "Val Acc: 0.7917, Val F1 Macro: 0.6271, Val F1 Weighted: 0.7439, Val Geometric Mean: 0.7175\n",
      "Test Acc: 0.7917, Test F1 Macro: 0.6271, Test F1 Weighted: 0.7439\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  20%|██        | 60/300 [00:33<02:20,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 060:\n",
      "Train Loss: 0.6798, Train Acc: 0.7506, Train F1 Macro: 0.6150, Train F1 Weighted: 0.7107\n",
      "Val Acc: 0.7500, Val F1 Macro: 0.6328, Val F1 Weighted: 0.7177, Val Geometric Mean: 0.6984\n",
      "Test Acc: 0.7500, Test F1 Macro: 0.6328, Test F1 Weighted: 0.7177\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  23%|██▎       | 70/300 [00:38<02:13,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 070:\n",
      "Train Loss: 0.5918, Train Acc: 0.7922, Train F1 Macro: 0.7174, Train F1 Weighted: 0.7696\n",
      "Val Acc: 0.8021, Val F1 Macro: 0.7543, Val F1 Weighted: 0.7913, Val Geometric Mean: 0.7823\n",
      "Test Acc: 0.8021, Test F1 Macro: 0.7543, Test F1 Weighted: 0.7913\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  27%|██▋       | 80/300 [00:44<02:09,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 080:\n",
      "Train Loss: 0.4628, Train Acc: 0.8571, Train F1 Macro: 0.8074, Train F1 Weighted: 0.8477\n",
      "Val Acc: 0.7917, Val F1 Macro: 0.7443, Val F1 Weighted: 0.7807, Val Geometric Mean: 0.7720\n",
      "Test Acc: 0.7917, Test F1 Macro: 0.7443, Test F1 Weighted: 0.7807\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  30%|███       | 90/300 [00:49<02:00,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 090:\n",
      "Train Loss: 0.4346, Train Acc: 0.8727, Train F1 Macro: 0.8474, Train F1 Weighted: 0.8717\n",
      "Val Acc: 0.7812, Val F1 Macro: 0.7704, Val F1 Weighted: 0.7861, Val Geometric Mean: 0.7792\n",
      "Test Acc: 0.7812, Test F1 Macro: 0.7704, Test F1 Weighted: 0.7861\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  33%|███▎      | 100/300 [00:55<01:57,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 100:\n",
      "Train Loss: 0.3548, Train Acc: 0.8753, Train F1 Macro: 0.8523, Train F1 Weighted: 0.8750\n",
      "Val Acc: 0.8542, Val F1 Macro: 0.8476, Val F1 Weighted: 0.8532, Val Geometric Mean: 0.8516\n",
      "Test Acc: 0.8542, Test F1 Macro: 0.8476, Test F1 Weighted: 0.8532\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  37%|███▋      | 110/300 [01:00<01:51,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 110:\n",
      "Train Loss: 0.2675, Train Acc: 0.9247, Train F1 Macro: 0.9113, Train F1 Weighted: 0.9234\n",
      "Val Acc: 0.8333, Val F1 Macro: 0.8330, Val F1 Weighted: 0.8305, Val Geometric Mean: 0.8323\n",
      "Test Acc: 0.8333, Test F1 Macro: 0.8330, Test F1 Weighted: 0.8305\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  40%|████      | 120/300 [01:06<01:44,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 120:\n",
      "Train Loss: 0.2084, Train Acc: 0.9506, Train F1 Macro: 0.9421, Train F1 Weighted: 0.9507\n",
      "Val Acc: 0.8333, Val F1 Macro: 0.8325, Val F1 Weighted: 0.8314, Val Geometric Mean: 0.8324\n",
      "Test Acc: 0.8333, Test F1 Macro: 0.8325, Test F1 Weighted: 0.8314\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  43%|████▎     | 130/300 [01:11<01:39,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 130:\n",
      "Train Loss: 0.2301, Train Acc: 0.9247, Train F1 Macro: 0.9144, Train F1 Weighted: 0.9248\n",
      "Val Acc: 0.8125, Val F1 Macro: 0.8126, Val F1 Weighted: 0.8129, Val Geometric Mean: 0.8127\n",
      "Test Acc: 0.8125, Test F1 Macro: 0.8126, Test F1 Weighted: 0.8129\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  47%|████▋     | 140/300 [01:17<01:33,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 140:\n",
      "Train Loss: 0.1531, Train Acc: 0.9662, Train F1 Macro: 0.9575, Train F1 Weighted: 0.9662\n",
      "Val Acc: 0.8125, Val F1 Macro: 0.8249, Val F1 Weighted: 0.8141, Val Geometric Mean: 0.8172\n",
      "Test Acc: 0.8125, Test F1 Macro: 0.8249, Test F1 Weighted: 0.8141\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  50%|█████     | 150/300 [01:22<01:27,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 150:\n",
      "Train Loss: 0.1372, Train Acc: 0.9532, Train F1 Macro: 0.9426, Train F1 Weighted: 0.9533\n",
      "Val Acc: 0.7812, Val F1 Macro: 0.7837, Val F1 Weighted: 0.7873, Val Geometric Mean: 0.7841\n",
      "Test Acc: 0.7812, Test F1 Macro: 0.7837, Test F1 Weighted: 0.7873\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  53%|█████▎    | 160/300 [01:28<01:21,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 160:\n",
      "Train Loss: 0.1149, Train Acc: 0.9714, Train F1 Macro: 0.9659, Train F1 Weighted: 0.9714\n",
      "Val Acc: 0.8229, Val F1 Macro: 0.8383, Val F1 Weighted: 0.8220, Val Geometric Mean: 0.8277\n",
      "Test Acc: 0.8229, Test F1 Macro: 0.8383, Test F1 Weighted: 0.8220\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  57%|█████▋    | 170/300 [01:33<01:15,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 170:\n",
      "Train Loss: 0.1111, Train Acc: 0.9766, Train F1 Macro: 0.9722, Train F1 Weighted: 0.9765\n",
      "Val Acc: 0.8125, Val F1 Macro: 0.8249, Val F1 Weighted: 0.8141, Val Geometric Mean: 0.8172\n",
      "Test Acc: 0.8125, Test F1 Macro: 0.8249, Test F1 Weighted: 0.8141\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  60%|██████    | 180/300 [01:39<01:10,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 180:\n",
      "Train Loss: 0.0890, Train Acc: 0.9870, Train F1 Macro: 0.9841, Train F1 Weighted: 0.9870\n",
      "Val Acc: 0.8021, Val F1 Macro: 0.8186, Val F1 Weighted: 0.8026, Val Geometric Mean: 0.8077\n",
      "Test Acc: 0.8021, Test F1 Macro: 0.8186, Test F1 Weighted: 0.8026\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  63%|██████▎   | 190/300 [01:44<01:04,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 190:\n",
      "Train Loss: 0.1071, Train Acc: 0.9688, Train F1 Macro: 0.9607, Train F1 Weighted: 0.9689\n",
      "Val Acc: 0.8229, Val F1 Macro: 0.8247, Val F1 Weighted: 0.8221, Val Geometric Mean: 0.8232\n",
      "Test Acc: 0.8229, Test F1 Macro: 0.8247, Test F1 Weighted: 0.8221\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  67%|██████▋   | 200/300 [01:50<00:57,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 200:\n",
      "Train Loss: 0.0702, Train Acc: 0.9870, Train F1 Macro: 0.9874, Train F1 Weighted: 0.9870\n",
      "Val Acc: 0.8125, Val F1 Macro: 0.8311, Val F1 Weighted: 0.8120, Val Geometric Mean: 0.8185\n",
      "Test Acc: 0.8125, Test F1 Macro: 0.8311, Test F1 Weighted: 0.8120\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  70%|███████   | 210/300 [01:55<00:52,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 210:\n",
      "Train Loss: 0.0767, Train Acc: 0.9818, Train F1 Macro: 0.9790, Train F1 Weighted: 0.9818\n",
      "Val Acc: 0.8438, Val F1 Macro: 0.8460, Val F1 Weighted: 0.8424, Val Geometric Mean: 0.8441\n",
      "Test Acc: 0.8438, Test F1 Macro: 0.8460, Test F1 Weighted: 0.8424\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  73%|███████▎  | 220/300 [02:01<00:46,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 220:\n",
      "Train Loss: 0.0581, Train Acc: 0.9870, Train F1 Macro: 0.9884, Train F1 Weighted: 0.9870\n",
      "Val Acc: 0.8229, Val F1 Macro: 0.8250, Val F1 Weighted: 0.8212, Val Geometric Mean: 0.8230\n",
      "Test Acc: 0.8229, Test F1 Macro: 0.8250, Test F1 Weighted: 0.8212\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  77%|███████▋  | 230/300 [02:06<00:40,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 230:\n",
      "Train Loss: 0.1532, Train Acc: 0.9506, Train F1 Macro: 0.9561, Train F1 Weighted: 0.9510\n",
      "Val Acc: 0.7917, Val F1 Macro: 0.7745, Val F1 Weighted: 0.7811, Val Geometric Mean: 0.7824\n",
      "Test Acc: 0.7917, Test F1 Macro: 0.7745, Test F1 Weighted: 0.7811\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  80%|████████  | 240/300 [02:12<00:34,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 240:\n",
      "Train Loss: 0.2097, Train Acc: 0.9351, Train F1 Macro: 0.9363, Train F1 Weighted: 0.9358\n",
      "Val Acc: 0.8229, Val F1 Macro: 0.8288, Val F1 Weighted: 0.8242, Val Geometric Mean: 0.8253\n",
      "Test Acc: 0.8229, Test F1 Macro: 0.8288, Test F1 Weighted: 0.8242\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  83%|████████▎ | 250/300 [02:17<00:29,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 250:\n",
      "Train Loss: 0.0828, Train Acc: 0.9792, Train F1 Macro: 0.9742, Train F1 Weighted: 0.9791\n",
      "Val Acc: 0.8438, Val F1 Macro: 0.8413, Val F1 Weighted: 0.8431, Val Geometric Mean: 0.8427\n",
      "Test Acc: 0.8438, Test F1 Macro: 0.8413, Test F1 Weighted: 0.8431\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  87%|████████▋ | 260/300 [02:23<00:23,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 260:\n",
      "Train Loss: 0.0731, Train Acc: 0.9766, Train F1 Macro: 0.9745, Train F1 Weighted: 0.9766\n",
      "Val Acc: 0.8333, Val F1 Macro: 0.8409, Val F1 Weighted: 0.8346, Val Geometric Mean: 0.8362\n",
      "Test Acc: 0.8333, Test F1 Macro: 0.8409, Test F1 Weighted: 0.8346\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  90%|█████████ | 270/300 [02:28<00:17,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 270:\n",
      "Train Loss: 0.0641, Train Acc: 0.9844, Train F1 Macro: 0.9822, Train F1 Weighted: 0.9844\n",
      "Val Acc: 0.8021, Val F1 Macro: 0.8090, Val F1 Weighted: 0.8016, Val Geometric Mean: 0.8042\n",
      "Test Acc: 0.8021, Test F1 Macro: 0.8090, Test F1 Weighted: 0.8016\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  93%|█████████▎| 280/300 [02:34<00:11,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 280:\n",
      "Train Loss: 0.0682, Train Acc: 0.9818, Train F1 Macro: 0.9828, Train F1 Weighted: 0.9817\n",
      "Val Acc: 0.8333, Val F1 Macro: 0.8396, Val F1 Weighted: 0.8320, Val Geometric Mean: 0.8350\n",
      "Test Acc: 0.8333, Test F1 Macro: 0.8396, Test F1 Weighted: 0.8320\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  97%|█████████▋| 290/300 [02:39<00:05,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 290:\n",
      "Train Loss: 0.0684, Train Acc: 0.9818, Train F1 Macro: 0.9767, Train F1 Weighted: 0.9819\n",
      "Val Acc: 0.8229, Val F1 Macro: 0.8270, Val F1 Weighted: 0.8224, Val Geometric Mean: 0.8241\n",
      "Test Acc: 0.8229, Test F1 Macro: 0.8270, Test F1 Weighted: 0.8224\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 300/300 [02:45<00:00,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 300:\n",
      "Train Loss: 0.0514, Train Acc: 0.9870, Train F1 Macro: 0.9848, Train F1 Weighted: 0.9871\n",
      "Val Acc: 0.8229, Val F1 Macro: 0.8304, Val F1 Weighted: 0.8234, Val Geometric Mean: 0.8256\n",
      "Test Acc: 0.8229, Test F1 Macro: 0.8304, Test F1 Weighted: 0.8234\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "isolated sample nodes, isolated gene nodes, mean degree: \n",
      "tensor(23) tensor(67) tensor(33.3181)\n",
      "isolated sample nodes, isolated gene nodes, mean degree: \n",
      "tensor(18) tensor(0) tensor(13.1642)\n",
      "isolated sample nodes, isolated gene nodes, mean degree: \n",
      "tensor(8) tensor(646) tensor(35.2536)\n",
      "isolated sample nodes, isolated gene nodes, mean degree: \n",
      "tensor(8) tensor(646) tensor(35.2536)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:   3%|▎         | 10/300 [00:05<02:43,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 010:\n",
      "Train Loss: 1.2542, Train Acc: 0.4597, Train F1 Macro: 0.1712, Train F1 Weighted: 0.2995\n",
      "Val Acc: 0.4583, Val F1 Macro: 0.1571, Val F1 Weighted: 0.2881, Val Geometric Mean: 0.2748\n",
      "Test Acc: 0.4583, Test F1 Macro: 0.1571, Test F1 Weighted: 0.2881\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:   7%|▋         | 20/300 [00:10<02:36,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 020:\n",
      "Train Loss: 1.1896, Train Acc: 0.4623, Train F1 Macro: 0.1979, Train F1 Weighted: 0.3242\n",
      "Val Acc: 0.4583, Val F1 Macro: 0.1571, Val F1 Weighted: 0.2881, Val Geometric Mean: 0.2748\n",
      "Test Acc: 0.4583, Test F1 Macro: 0.1571, Test F1 Weighted: 0.2881\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  10%|█         | 30/300 [00:15<02:33,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 030:\n",
      "Train Loss: 1.0586, Train Acc: 0.5169, Train F1 Macro: 0.3197, Train F1 Weighted: 0.4236\n",
      "Val Acc: 0.6042, Val F1 Macro: 0.4266, Val F1 Weighted: 0.5148, Val Geometric Mean: 0.5100\n",
      "Test Acc: 0.6042, Test F1 Macro: 0.4266, Test F1 Weighted: 0.5148\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  13%|█▎        | 40/300 [00:21<02:27,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 040:\n",
      "Train Loss: 0.9299, Train Acc: 0.6338, Train F1 Macro: 0.4881, Train F1 Weighted: 0.5727\n",
      "Val Acc: 0.7188, Val F1 Macro: 0.5701, Val F1 Weighted: 0.6615, Val Geometric Mean: 0.6472\n",
      "Test Acc: 0.7188, Test F1 Macro: 0.5701, Test F1 Weighted: 0.6615\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  17%|█▋        | 50/300 [00:26<02:21,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 050:\n",
      "Train Loss: 0.8140, Train Acc: 0.7169, Train F1 Macro: 0.5897, Train F1 Weighted: 0.6756\n",
      "Val Acc: 0.7604, Val F1 Macro: 0.6141, Val F1 Weighted: 0.7129, Val Geometric Mean: 0.6930\n",
      "Test Acc: 0.7604, Test F1 Macro: 0.6141, Test F1 Weighted: 0.7129\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  20%|██        | 60/300 [00:31<02:15,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 060:\n",
      "Train Loss: 0.6702, Train Acc: 0.7506, Train F1 Macro: 0.6168, Train F1 Weighted: 0.7072\n",
      "Val Acc: 0.7500, Val F1 Macro: 0.6041, Val F1 Weighted: 0.7006, Val Geometric Mean: 0.6822\n",
      "Test Acc: 0.7500, Test F1 Macro: 0.6041, Test F1 Weighted: 0.7006\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  23%|██▎       | 70/300 [00:37<02:08,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 070:\n",
      "Train Loss: 0.5760, Train Acc: 0.8052, Train F1 Macro: 0.7432, Train F1 Weighted: 0.7888\n",
      "Val Acc: 0.7917, Val F1 Macro: 0.7487, Val F1 Weighted: 0.7797, Val Geometric Mean: 0.7732\n",
      "Test Acc: 0.7917, Test F1 Macro: 0.7487, Test F1 Weighted: 0.7797\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  27%|██▋       | 80/300 [00:42<02:03,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 080:\n",
      "Train Loss: 0.4442, Train Acc: 0.8597, Train F1 Macro: 0.8180, Train F1 Weighted: 0.8543\n",
      "Val Acc: 0.8229, Val F1 Macro: 0.8025, Val F1 Weighted: 0.8150, Val Geometric Mean: 0.8134\n",
      "Test Acc: 0.8229, Test F1 Macro: 0.8025, Test F1 Weighted: 0.8150\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  30%|███       | 90/300 [00:47<01:58,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 090:\n",
      "Train Loss: 0.3516, Train Acc: 0.9143, Train F1 Macro: 0.9009, Train F1 Weighted: 0.9146\n",
      "Val Acc: 0.8021, Val F1 Macro: 0.7960, Val F1 Weighted: 0.7971, Val Geometric Mean: 0.7984\n",
      "Test Acc: 0.8021, Test F1 Macro: 0.7960, Test F1 Weighted: 0.7971\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  33%|███▎      | 100/300 [00:53<01:52,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 100:\n",
      "Train Loss: 0.3188, Train Acc: 0.9091, Train F1 Macro: 0.9101, Train F1 Weighted: 0.9103\n",
      "Val Acc: 0.8229, Val F1 Macro: 0.8109, Val F1 Weighted: 0.8204, Val Geometric Mean: 0.8181\n",
      "Test Acc: 0.8229, Test F1 Macro: 0.8109, Test F1 Weighted: 0.8204\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  37%|███▋      | 110/300 [00:58<01:46,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 110:\n",
      "Train Loss: 0.2588, Train Acc: 0.9377, Train F1 Macro: 0.9326, Train F1 Weighted: 0.9373\n",
      "Val Acc: 0.8125, Val F1 Macro: 0.8075, Val F1 Weighted: 0.8116, Val Geometric Mean: 0.8105\n",
      "Test Acc: 0.8125, Test F1 Macro: 0.8075, Test F1 Weighted: 0.8116\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  40%|████      | 120/300 [01:03<01:41,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 120:\n",
      "Train Loss: 0.1819, Train Acc: 0.9688, Train F1 Macro: 0.9644, Train F1 Weighted: 0.9689\n",
      "Val Acc: 0.8438, Val F1 Macro: 0.8392, Val F1 Weighted: 0.8415, Val Geometric Mean: 0.8415\n",
      "Test Acc: 0.8438, Test F1 Macro: 0.8392, Test F1 Weighted: 0.8415\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  43%|████▎     | 130/300 [01:09<01:34,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 130:\n",
      "Train Loss: 0.1219, Train Acc: 0.9740, Train F1 Macro: 0.9722, Train F1 Weighted: 0.9741\n",
      "Val Acc: 0.8333, Val F1 Macro: 0.8364, Val F1 Weighted: 0.8310, Val Geometric Mean: 0.8336\n",
      "Test Acc: 0.8333, Test F1 Macro: 0.8364, Test F1 Weighted: 0.8310\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  47%|████▋     | 140/300 [01:14<01:29,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 140:\n",
      "Train Loss: 0.1196, Train Acc: 0.9714, Train F1 Macro: 0.9666, Train F1 Weighted: 0.9714\n",
      "Val Acc: 0.8438, Val F1 Macro: 0.8409, Val F1 Weighted: 0.8386, Val Geometric Mean: 0.8411\n",
      "Test Acc: 0.8438, Test F1 Macro: 0.8409, Test F1 Weighted: 0.8386\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  50%|█████     | 150/300 [01:19<01:24,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 150:\n",
      "Train Loss: 0.1125, Train Acc: 0.9766, Train F1 Macro: 0.9767, Train F1 Weighted: 0.9766\n",
      "Val Acc: 0.7708, Val F1 Macro: 0.7611, Val F1 Weighted: 0.7707, Val Geometric Mean: 0.7675\n",
      "Test Acc: 0.7708, Test F1 Macro: 0.7611, Test F1 Weighted: 0.7707\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  53%|█████▎    | 160/300 [01:25<01:20,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 160:\n",
      "Train Loss: 0.1097, Train Acc: 0.9714, Train F1 Macro: 0.9679, Train F1 Weighted: 0.9715\n",
      "Val Acc: 0.8021, Val F1 Macro: 0.8063, Val F1 Weighted: 0.7996, Val Geometric Mean: 0.8026\n",
      "Test Acc: 0.8021, Test F1 Macro: 0.8063, Test F1 Weighted: 0.7996\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  57%|█████▋    | 170/300 [01:30<01:13,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 170:\n",
      "Train Loss: 0.0954, Train Acc: 0.9662, Train F1 Macro: 0.9600, Train F1 Weighted: 0.9661\n",
      "Val Acc: 0.8021, Val F1 Macro: 0.8075, Val F1 Weighted: 0.8019, Val Geometric Mean: 0.8038\n",
      "Test Acc: 0.8021, Test F1 Macro: 0.8075, Test F1 Weighted: 0.8019\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  60%|██████    | 180/300 [01:35<01:07,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 180:\n",
      "Train Loss: 0.0857, Train Acc: 0.9792, Train F1 Macro: 0.9747, Train F1 Weighted: 0.9793\n",
      "Val Acc: 0.8021, Val F1 Macro: 0.8132, Val F1 Weighted: 0.8008, Val Geometric Mean: 0.8053\n",
      "Test Acc: 0.8021, Test F1 Macro: 0.8132, Test F1 Weighted: 0.8008\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  63%|██████▎   | 190/300 [01:41<01:01,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 190:\n",
      "Train Loss: 0.0780, Train Acc: 0.9740, Train F1 Macro: 0.9643, Train F1 Weighted: 0.9741\n",
      "Val Acc: 0.7917, Val F1 Macro: 0.7994, Val F1 Weighted: 0.7900, Val Geometric Mean: 0.7937\n",
      "Test Acc: 0.7917, Test F1 Macro: 0.7994, Test F1 Weighted: 0.7900\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  67%|██████▋   | 200/300 [01:46<00:56,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 200:\n",
      "Train Loss: 0.0784, Train Acc: 0.9766, Train F1 Macro: 0.9751, Train F1 Weighted: 0.9766\n",
      "Val Acc: 0.7812, Val F1 Macro: 0.7915, Val F1 Weighted: 0.7812, Val Geometric Mean: 0.7847\n",
      "Test Acc: 0.7812, Test F1 Macro: 0.7915, Test F1 Weighted: 0.7812\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  70%|███████   | 210/300 [01:51<00:52,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 210:\n",
      "Train Loss: 0.0402, Train Acc: 0.9948, Train F1 Macro: 0.9934, Train F1 Weighted: 0.9948\n",
      "Val Acc: 0.7812, Val F1 Macro: 0.7647, Val F1 Weighted: 0.7697, Val Geometric Mean: 0.7719\n",
      "Test Acc: 0.7812, Test F1 Macro: 0.7647, Test F1 Weighted: 0.7697\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  73%|███████▎  | 220/300 [01:57<00:46,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 220:\n",
      "Train Loss: 0.1006, Train Acc: 0.9662, Train F1 Macro: 0.9707, Train F1 Weighted: 0.9662\n",
      "Val Acc: 0.8021, Val F1 Macro: 0.8017, Val F1 Weighted: 0.7988, Val Geometric Mean: 0.8008\n",
      "Test Acc: 0.8021, Test F1 Macro: 0.8017, Test F1 Weighted: 0.7988\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  77%|███████▋  | 230/300 [02:02<00:39,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 230:\n",
      "Train Loss: 0.0554, Train Acc: 0.9896, Train F1 Macro: 0.9899, Train F1 Weighted: 0.9896\n",
      "Val Acc: 0.8229, Val F1 Macro: 0.8416, Val F1 Weighted: 0.8243, Val Geometric Mean: 0.8296\n",
      "Test Acc: 0.8229, Test F1 Macro: 0.8416, Test F1 Weighted: 0.8243\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  80%|████████  | 240/300 [02:08<00:35,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 240:\n",
      "Train Loss: 0.0664, Train Acc: 0.9896, Train F1 Macro: 0.9868, Train F1 Weighted: 0.9897\n",
      "Val Acc: 0.7917, Val F1 Macro: 0.7935, Val F1 Weighted: 0.7893, Val Geometric Mean: 0.7915\n",
      "Test Acc: 0.7917, Test F1 Macro: 0.7935, Test F1 Weighted: 0.7893\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  83%|████████▎ | 250/300 [02:13<00:28,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 250:\n",
      "Train Loss: 0.0441, Train Acc: 0.9896, Train F1 Macro: 0.9867, Train F1 Weighted: 0.9896\n",
      "Val Acc: 0.8125, Val F1 Macro: 0.8169, Val F1 Weighted: 0.8079, Val Geometric Mean: 0.8124\n",
      "Test Acc: 0.8125, Test F1 Macro: 0.8169, Test F1 Weighted: 0.8079\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  87%|████████▋ | 260/300 [02:19<00:22,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 260:\n",
      "Train Loss: 0.0544, Train Acc: 0.9818, Train F1 Macro: 0.9813, Train F1 Weighted: 0.9818\n",
      "Val Acc: 0.8125, Val F1 Macro: 0.8213, Val F1 Weighted: 0.8126, Val Geometric Mean: 0.8155\n",
      "Test Acc: 0.8125, Test F1 Macro: 0.8213, Test F1 Weighted: 0.8126\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  90%|█████████ | 270/300 [02:24<00:16,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 270:\n",
      "Train Loss: 0.0375, Train Acc: 0.9922, Train F1 Macro: 0.9929, Train F1 Weighted: 0.9922\n",
      "Val Acc: 0.7917, Val F1 Macro: 0.8008, Val F1 Weighted: 0.7924, Val Geometric Mean: 0.7949\n",
      "Test Acc: 0.7917, Test F1 Macro: 0.8008, Test F1 Weighted: 0.7924\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  93%|█████████▎| 280/300 [02:29<00:11,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 280:\n",
      "Train Loss: 0.0414, Train Acc: 0.9896, Train F1 Macro: 0.9894, Train F1 Weighted: 0.9896\n",
      "Val Acc: 0.8021, Val F1 Macro: 0.8075, Val F1 Weighted: 0.8019, Val Geometric Mean: 0.8038\n",
      "Test Acc: 0.8021, Test F1 Macro: 0.8075, Test F1 Weighted: 0.8019\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  97%|█████████▋| 290/300 [02:35<00:05,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 290:\n",
      "Train Loss: 0.0452, Train Acc: 0.9922, Train F1 Macro: 0.9914, Train F1 Weighted: 0.9922\n",
      "Val Acc: 0.8125, Val F1 Macro: 0.8116, Val F1 Weighted: 0.8094, Val Geometric Mean: 0.8112\n",
      "Test Acc: 0.8125, Test F1 Macro: 0.8116, Test F1 Weighted: 0.8094\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 300/300 [02:40<00:00,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 300:\n",
      "Train Loss: 0.0271, Train Acc: 0.9974, Train F1 Macro: 0.9975, Train F1 Weighted: 0.9974\n",
      "Val Acc: 0.7812, Val F1 Macro: 0.7935, Val F1 Weighted: 0.7776, Val Geometric Mean: 0.7841\n",
      "Test Acc: 0.7812, Test F1 Macro: 0.7935, Test F1 Weighted: 0.7776\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "isolated sample nodes, isolated gene nodes, mean degree: \n",
      "tensor(23) tensor(71) tensor(33.4304)\n",
      "isolated sample nodes, isolated gene nodes, mean degree: \n",
      "tensor(18) tensor(0) tensor(13.1642)\n",
      "isolated sample nodes, isolated gene nodes, mean degree: \n",
      "tensor(11) tensor(652) tensor(34.5925)\n",
      "isolated sample nodes, isolated gene nodes, mean degree: \n",
      "tensor(11) tensor(652) tensor(34.5925)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:   3%|▎         | 10/300 [00:05<02:48,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 010:\n",
      "Train Loss: 1.2572, Train Acc: 0.4545, Train F1 Macro: 0.1658, Train F1 Weighted: 0.2937\n",
      "Val Acc: 0.4583, Val F1 Macro: 0.1571, Val F1 Weighted: 0.2881, Val Geometric Mean: 0.2748\n",
      "Test Acc: 0.4583, Test F1 Macro: 0.1571, Test F1 Weighted: 0.2881\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:   7%|▋         | 20/300 [00:10<02:41,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 020:\n",
      "Train Loss: 1.1494, Train Acc: 0.4545, Train F1 Macro: 0.2216, Train F1 Weighted: 0.3422\n",
      "Val Acc: 0.4688, Val F1 Macro: 0.1783, Val F1 Weighted: 0.3102, Val Geometric Mean: 0.2959\n",
      "Test Acc: 0.4688, Test F1 Macro: 0.1783, Test F1 Weighted: 0.3102\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  10%|█         | 30/300 [00:16<02:38,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 030:\n",
      "Train Loss: 1.0159, Train Acc: 0.6104, Train F1 Macro: 0.4600, Train F1 Weighted: 0.5510\n",
      "Val Acc: 0.6458, Val F1 Macro: 0.4593, Val F1 Weighted: 0.5489, Val Geometric Mean: 0.5461\n",
      "Test Acc: 0.6458, Test F1 Macro: 0.4593, Test F1 Weighted: 0.5489\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  13%|█▎        | 40/300 [00:21<02:29,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 040:\n",
      "Train Loss: 0.8721, Train Acc: 0.7143, Train F1 Macro: 0.5694, Train F1 Weighted: 0.6665\n",
      "Val Acc: 0.7083, Val F1 Macro: 0.5505, Val F1 Weighted: 0.6480, Val Geometric Mean: 0.6322\n",
      "Test Acc: 0.7083, Test F1 Macro: 0.5505, Test F1 Weighted: 0.6480\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  17%|█▋        | 50/300 [00:27<02:24,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 050:\n",
      "Train Loss: 0.7939, Train Acc: 0.7195, Train F1 Macro: 0.5755, Train F1 Weighted: 0.6722\n",
      "Val Acc: 0.6875, Val F1 Macro: 0.5100, Val F1 Weighted: 0.6077, Val Geometric Mean: 0.5973\n",
      "Test Acc: 0.6875, Test F1 Macro: 0.5100, Test F1 Weighted: 0.6077\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  20%|██        | 60/300 [00:32<02:18,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 060:\n",
      "Train Loss: 0.6764, Train Acc: 0.7532, Train F1 Macro: 0.6405, Train F1 Weighted: 0.7217\n",
      "Val Acc: 0.7396, Val F1 Macro: 0.6289, Val F1 Weighted: 0.7042, Val Geometric Mean: 0.6893\n",
      "Test Acc: 0.7396, Test F1 Macro: 0.6289, Test F1 Weighted: 0.7042\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  23%|██▎       | 70/300 [00:38<02:13,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 070:\n",
      "Train Loss: 0.5713, Train Acc: 0.8260, Train F1 Macro: 0.7528, Train F1 Weighted: 0.8066\n",
      "Val Acc: 0.7917, Val F1 Macro: 0.7746, Val F1 Weighted: 0.7860, Val Geometric Mean: 0.7840\n",
      "Test Acc: 0.7917, Test F1 Macro: 0.7746, Test F1 Weighted: 0.7860\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  27%|██▋       | 80/300 [00:43<02:07,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 080:\n",
      "Train Loss: 0.4884, Train Acc: 0.8338, Train F1 Macro: 0.7774, Train F1 Weighted: 0.8270\n",
      "Val Acc: 0.7500, Val F1 Macro: 0.7242, Val F1 Weighted: 0.7426, Val Geometric Mean: 0.7388\n",
      "Test Acc: 0.7500, Test F1 Macro: 0.7242, Test F1 Weighted: 0.7426\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  30%|███       | 90/300 [00:49<02:01,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 090:\n",
      "Train Loss: 0.4272, Train Acc: 0.8649, Train F1 Macro: 0.8598, Train F1 Weighted: 0.8648\n",
      "Val Acc: 0.7812, Val F1 Macro: 0.7729, Val F1 Weighted: 0.7778, Val Geometric Mean: 0.7773\n",
      "Test Acc: 0.7812, Test F1 Macro: 0.7729, Test F1 Weighted: 0.7778\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  33%|███▎      | 100/300 [00:54<01:55,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 100:\n",
      "Train Loss: 0.2783, Train Acc: 0.9247, Train F1 Macro: 0.9144, Train F1 Weighted: 0.9242\n",
      "Val Acc: 0.7917, Val F1 Macro: 0.7928, Val F1 Weighted: 0.7887, Val Geometric Mean: 0.7910\n",
      "Test Acc: 0.7917, Test F1 Macro: 0.7928, Test F1 Weighted: 0.7887\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  37%|███▋      | 110/300 [01:00<01:50,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 110:\n",
      "Train Loss: 0.2355, Train Acc: 0.9299, Train F1 Macro: 0.9170, Train F1 Weighted: 0.9295\n",
      "Val Acc: 0.7812, Val F1 Macro: 0.7845, Val F1 Weighted: 0.7738, Val Geometric Mean: 0.7798\n",
      "Test Acc: 0.7812, Test F1 Macro: 0.7845, Test F1 Weighted: 0.7738\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  40%|████      | 120/300 [01:05<01:43,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 120:\n",
      "Train Loss: 0.2444, Train Acc: 0.9299, Train F1 Macro: 0.9335, Train F1 Weighted: 0.9291\n",
      "Val Acc: 0.8021, Val F1 Macro: 0.7928, Val F1 Weighted: 0.7910, Val Geometric Mean: 0.7953\n",
      "Test Acc: 0.8021, Test F1 Macro: 0.7928, Test F1 Weighted: 0.7910\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  43%|████▎     | 130/300 [01:11<01:37,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 130:\n",
      "Train Loss: 0.2037, Train Acc: 0.9377, Train F1 Macro: 0.9328, Train F1 Weighted: 0.9379\n",
      "Val Acc: 0.8021, Val F1 Macro: 0.8046, Val F1 Weighted: 0.7933, Val Geometric Mean: 0.8000\n",
      "Test Acc: 0.8021, Test F1 Macro: 0.8046, Test F1 Weighted: 0.7933\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  47%|████▋     | 140/300 [01:16<01:32,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 140:\n",
      "Train Loss: 0.1306, Train Acc: 0.9688, Train F1 Macro: 0.9723, Train F1 Weighted: 0.9688\n",
      "Val Acc: 0.8229, Val F1 Macro: 0.8217, Val F1 Weighted: 0.8148, Val Geometric Mean: 0.8198\n",
      "Test Acc: 0.8229, Test F1 Macro: 0.8217, Test F1 Weighted: 0.8148\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  50%|█████     | 150/300 [01:21<01:27,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 150:\n",
      "Train Loss: 0.1181, Train Acc: 0.9714, Train F1 Macro: 0.9670, Train F1 Weighted: 0.9714\n",
      "Val Acc: 0.8021, Val F1 Macro: 0.8046, Val F1 Weighted: 0.7933, Val Geometric Mean: 0.8000\n",
      "Test Acc: 0.8021, Test F1 Macro: 0.8046, Test F1 Weighted: 0.7933\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  53%|█████▎    | 160/300 [01:27<01:21,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 160:\n",
      "Train Loss: 0.1090, Train Acc: 0.9766, Train F1 Macro: 0.9793, Train F1 Weighted: 0.9766\n",
      "Val Acc: 0.7708, Val F1 Macro: 0.7625, Val F1 Weighted: 0.7662, Val Geometric Mean: 0.7665\n",
      "Test Acc: 0.7708, Test F1 Macro: 0.7625, Test F1 Weighted: 0.7662\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  57%|█████▋    | 170/300 [01:32<01:15,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 170:\n",
      "Train Loss: 0.0854, Train Acc: 0.9844, Train F1 Macro: 0.9805, Train F1 Weighted: 0.9844\n",
      "Val Acc: 0.7917, Val F1 Macro: 0.7937, Val F1 Weighted: 0.7807, Val Geometric Mean: 0.7887\n",
      "Test Acc: 0.7917, Test F1 Macro: 0.7937, Test F1 Weighted: 0.7807\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  60%|██████    | 180/300 [01:38<01:09,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 180:\n",
      "Train Loss: 0.0649, Train Acc: 0.9870, Train F1 Macro: 0.9858, Train F1 Weighted: 0.9870\n",
      "Val Acc: 0.8125, Val F1 Macro: 0.8217, Val F1 Weighted: 0.8109, Val Geometric Mean: 0.8150\n",
      "Test Acc: 0.8125, Test F1 Macro: 0.8217, Test F1 Weighted: 0.8109\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  63%|██████▎   | 190/300 [01:43<01:03,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 190:\n",
      "Train Loss: 0.1088, Train Acc: 0.9688, Train F1 Macro: 0.9658, Train F1 Weighted: 0.9688\n",
      "Val Acc: 0.8229, Val F1 Macro: 0.8266, Val F1 Weighted: 0.8158, Val Geometric Mean: 0.8218\n",
      "Test Acc: 0.8229, Test F1 Macro: 0.8266, Test F1 Weighted: 0.8158\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  67%|██████▋   | 200/300 [01:49<00:57,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 200:\n",
      "Train Loss: 0.0896, Train Acc: 0.9766, Train F1 Macro: 0.9747, Train F1 Weighted: 0.9766\n",
      "Val Acc: 0.7812, Val F1 Macro: 0.7755, Val F1 Weighted: 0.7694, Val Geometric Mean: 0.7754\n",
      "Test Acc: 0.7812, Test F1 Macro: 0.7755, Test F1 Weighted: 0.7694\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  70%|███████   | 210/300 [01:54<00:52,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 210:\n",
      "Train Loss: 0.0828, Train Acc: 0.9818, Train F1 Macro: 0.9849, Train F1 Weighted: 0.9818\n",
      "Val Acc: 0.8125, Val F1 Macro: 0.8068, Val F1 Weighted: 0.8049, Val Geometric Mean: 0.8081\n",
      "Test Acc: 0.8125, Test F1 Macro: 0.8068, Test F1 Weighted: 0.8049\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  73%|███████▎  | 220/300 [02:00<00:46,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 220:\n",
      "Train Loss: 0.0678, Train Acc: 0.9896, Train F1 Macro: 0.9883, Train F1 Weighted: 0.9896\n",
      "Val Acc: 0.7812, Val F1 Macro: 0.7793, Val F1 Weighted: 0.7781, Val Geometric Mean: 0.7795\n",
      "Test Acc: 0.7812, Test F1 Macro: 0.7793, Test F1 Weighted: 0.7781\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  77%|███████▋  | 230/300 [02:05<00:40,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 230:\n",
      "Train Loss: 0.1125, Train Acc: 0.9636, Train F1 Macro: 0.9673, Train F1 Weighted: 0.9634\n",
      "Val Acc: 0.7917, Val F1 Macro: 0.8032, Val F1 Weighted: 0.7936, Val Geometric Mean: 0.7961\n",
      "Test Acc: 0.7917, Test F1 Macro: 0.8032, Test F1 Weighted: 0.7936\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  80%|████████  | 240/300 [02:11<00:35,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 240:\n",
      "Train Loss: 0.0595, Train Acc: 0.9844, Train F1 Macro: 0.9843, Train F1 Weighted: 0.9844\n",
      "Val Acc: 0.7917, Val F1 Macro: 0.7968, Val F1 Weighted: 0.7924, Val Geometric Mean: 0.7936\n",
      "Test Acc: 0.7917, Test F1 Macro: 0.7968, Test F1 Weighted: 0.7924\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  83%|████████▎ | 250/300 [02:16<00:28,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 250:\n",
      "Train Loss: 0.1896, Train Acc: 0.9377, Train F1 Macro: 0.9430, Train F1 Weighted: 0.9359\n",
      "Val Acc: 0.7917, Val F1 Macro: 0.7916, Val F1 Weighted: 0.7915, Val Geometric Mean: 0.7916\n",
      "Test Acc: 0.7917, Test F1 Macro: 0.7916, Test F1 Weighted: 0.7915\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  87%|████████▋ | 260/300 [02:22<00:23,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 260:\n",
      "Train Loss: 0.1122, Train Acc: 0.9584, Train F1 Macro: 0.9591, Train F1 Weighted: 0.9582\n",
      "Val Acc: 0.7604, Val F1 Macro: 0.7547, Val F1 Weighted: 0.7537, Val Geometric Mean: 0.7563\n",
      "Test Acc: 0.7604, Test F1 Macro: 0.7547, Test F1 Weighted: 0.7537\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  90%|█████████ | 270/300 [02:27<00:17,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 270:\n",
      "Train Loss: 0.0844, Train Acc: 0.9766, Train F1 Macro: 0.9784, Train F1 Weighted: 0.9766\n",
      "Val Acc: 0.7500, Val F1 Macro: 0.7461, Val F1 Weighted: 0.7453, Val Geometric Mean: 0.7471\n",
      "Test Acc: 0.7500, Test F1 Macro: 0.7461, Test F1 Weighted: 0.7453\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  93%|█████████▎| 280/300 [02:33<00:11,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 280:\n",
      "Train Loss: 0.0540, Train Acc: 0.9818, Train F1 Macro: 0.9797, Train F1 Weighted: 0.9819\n",
      "Val Acc: 0.7708, Val F1 Macro: 0.7611, Val F1 Weighted: 0.7598, Val Geometric Mean: 0.7639\n",
      "Test Acc: 0.7708, Test F1 Macro: 0.7611, Test F1 Weighted: 0.7598\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  97%|█████████▋| 290/300 [02:38<00:05,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 290:\n",
      "Train Loss: 0.0366, Train Acc: 0.9948, Train F1 Macro: 0.9934, Train F1 Weighted: 0.9948\n",
      "Val Acc: 0.7708, Val F1 Macro: 0.7551, Val F1 Weighted: 0.7588, Val Geometric Mean: 0.7615\n",
      "Test Acc: 0.7708, Test F1 Macro: 0.7551, Test F1 Weighted: 0.7588\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 300/300 [02:44<00:00,  1.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 300:\n",
      "Train Loss: 0.0525, Train Acc: 0.9870, Train F1 Macro: 0.9858, Train F1 Weighted: 0.9870\n",
      "Val Acc: 0.7708, Val F1 Macro: 0.7693, Val F1 Weighted: 0.7607, Val Geometric Mean: 0.7669\n",
      "Test Acc: 0.7708, Test F1 Macro: 0.7693, Test F1 Weighted: 0.7607\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "isolated sample nodes, isolated gene nodes, mean degree: \n",
      "tensor(22) tensor(67) tensor(33.6902)\n",
      "isolated sample nodes, isolated gene nodes, mean degree: \n",
      "tensor(18) tensor(0) tensor(13.1642)\n",
      "isolated sample nodes, isolated gene nodes, mean degree: \n",
      "tensor(6) tensor(659) tensor(34.7713)\n",
      "isolated sample nodes, isolated gene nodes, mean degree: \n",
      "tensor(6) tensor(659) tensor(34.7713)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:   3%|▎         | 10/300 [00:05<02:42,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 010:\n",
      "Train Loss: 1.2567, Train Acc: 0.4571, Train F1 Macro: 0.1620, Train F1 Weighted: 0.2922\n",
      "Val Acc: 0.4479, Val F1 Macro: 0.1547, Val F1 Weighted: 0.2771, Val Geometric Mean: 0.2678\n",
      "Test Acc: 0.4479, Test F1 Macro: 0.1547, Test F1 Weighted: 0.2771\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:   7%|▋         | 20/300 [00:10<02:38,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 020:\n",
      "Train Loss: 1.2009, Train Acc: 0.4442, Train F1 Macro: 0.1625, Train F1 Weighted: 0.2894\n",
      "Val Acc: 0.4479, Val F1 Macro: 0.1547, Val F1 Weighted: 0.2771, Val Geometric Mean: 0.2678\n",
      "Test Acc: 0.4479, Test F1 Macro: 0.1547, Test F1 Weighted: 0.2771\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  10%|█         | 30/300 [00:15<02:32,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 030:\n",
      "Train Loss: 1.0486, Train Acc: 0.5506, Train F1 Macro: 0.3757, Train F1 Weighted: 0.4742\n",
      "Val Acc: 0.6042, Val F1 Macro: 0.4078, Val F1 Weighted: 0.4767, Val Geometric Mean: 0.4897\n",
      "Test Acc: 0.6042, Test F1 Macro: 0.4078, Test F1 Weighted: 0.4767\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  13%|█▎        | 40/300 [00:21<02:26,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 040:\n",
      "Train Loss: 0.9442, Train Acc: 0.6286, Train F1 Macro: 0.4705, Train F1 Weighted: 0.5611\n",
      "Val Acc: 0.6875, Val F1 Macro: 0.5130, Val F1 Weighted: 0.6094, Val Geometric Mean: 0.5990\n",
      "Test Acc: 0.6875, Test F1 Macro: 0.5130, Test F1 Weighted: 0.6094\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  17%|█▋        | 50/300 [00:26<02:21,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 050:\n",
      "Train Loss: 0.8394, Train Acc: 0.6649, Train F1 Macro: 0.5182, Train F1 Weighted: 0.6102\n",
      "Val Acc: 0.6562, Val F1 Macro: 0.4753, Val F1 Weighted: 0.5683, Val Geometric Mean: 0.5617\n",
      "Test Acc: 0.6562, Test F1 Macro: 0.4753, Test F1 Weighted: 0.5683\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  20%|██        | 60/300 [00:31<02:15,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 060:\n",
      "Train Loss: 0.7519, Train Acc: 0.7065, Train F1 Macro: 0.5688, Train F1 Weighted: 0.6618\n",
      "Val Acc: 0.7188, Val F1 Macro: 0.5726, Val F1 Weighted: 0.6722, Val Geometric Mean: 0.6516\n",
      "Test Acc: 0.7188, Test F1 Macro: 0.5726, Test F1 Weighted: 0.6722\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  23%|██▎       | 70/300 [00:37<02:09,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 070:\n",
      "Train Loss: 0.6218, Train Acc: 0.7688, Train F1 Macro: 0.6540, Train F1 Weighted: 0.7398\n",
      "Val Acc: 0.7604, Val F1 Macro: 0.6389, Val F1 Weighted: 0.7281, Val Geometric Mean: 0.7072\n",
      "Test Acc: 0.7604, Test F1 Macro: 0.6389, Test F1 Weighted: 0.7281\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  27%|██▋       | 80/300 [00:42<02:02,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 080:\n",
      "Train Loss: 0.5277, Train Acc: 0.7870, Train F1 Macro: 0.7096, Train F1 Weighted: 0.7729\n",
      "Val Acc: 0.7500, Val F1 Macro: 0.6537, Val F1 Weighted: 0.7206, Val Geometric Mean: 0.7069\n",
      "Test Acc: 0.7500, Test F1 Macro: 0.6537, Test F1 Weighted: 0.7206\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  30%|███       | 90/300 [00:47<01:59,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 090:\n",
      "Train Loss: 0.4785, Train Acc: 0.8519, Train F1 Macro: 0.8095, Train F1 Weighted: 0.8458\n",
      "Val Acc: 0.7708, Val F1 Macro: 0.6989, Val F1 Weighted: 0.7534, Val Geometric Mean: 0.7404\n",
      "Test Acc: 0.7708, Test F1 Macro: 0.6989, Test F1 Weighted: 0.7534\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  33%|███▎      | 100/300 [00:53<01:51,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 100:\n",
      "Train Loss: 0.3663, Train Acc: 0.8805, Train F1 Macro: 0.8644, Train F1 Weighted: 0.8787\n",
      "Val Acc: 0.8021, Val F1 Macro: 0.7429, Val F1 Weighted: 0.7912, Val Geometric Mean: 0.7783\n",
      "Test Acc: 0.8021, Test F1 Macro: 0.7429, Test F1 Weighted: 0.7912\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  37%|███▋      | 110/300 [00:58<01:46,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 110:\n",
      "Train Loss: 0.3112, Train Acc: 0.9013, Train F1 Macro: 0.8784, Train F1 Weighted: 0.8988\n",
      "Val Acc: 0.8333, Val F1 Macro: 0.7653, Val F1 Weighted: 0.8257, Val Geometric Mean: 0.8075\n",
      "Test Acc: 0.8333, Test F1 Macro: 0.7653, Test F1 Weighted: 0.8257\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  40%|████      | 120/300 [01:03<01:40,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 120:\n",
      "Train Loss: 0.2566, Train Acc: 0.9273, Train F1 Macro: 0.9070, Train F1 Weighted: 0.9263\n",
      "Val Acc: 0.8229, Val F1 Macro: 0.7808, Val F1 Weighted: 0.8157, Val Geometric Mean: 0.8063\n",
      "Test Acc: 0.8229, Test F1 Macro: 0.7808, Test F1 Weighted: 0.8157\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  43%|████▎     | 130/300 [01:08<01:34,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 130:\n",
      "Train Loss: 0.2211, Train Acc: 0.9351, Train F1 Macro: 0.9302, Train F1 Weighted: 0.9340\n",
      "Val Acc: 0.8125, Val F1 Macro: 0.7647, Val F1 Weighted: 0.8137, Val Geometric Mean: 0.7966\n",
      "Test Acc: 0.8125, Test F1 Macro: 0.7647, Test F1 Weighted: 0.8137\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  47%|████▋     | 140/300 [01:14<01:28,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 140:\n",
      "Train Loss: 0.1590, Train Acc: 0.9558, Train F1 Macro: 0.9473, Train F1 Weighted: 0.9552\n",
      "Val Acc: 0.8021, Val F1 Macro: 0.7724, Val F1 Weighted: 0.8029, Val Geometric Mean: 0.7923\n",
      "Test Acc: 0.8021, Test F1 Macro: 0.7724, Test F1 Weighted: 0.8029\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  50%|█████     | 150/300 [01:19<01:23,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 150:\n",
      "Train Loss: 0.1364, Train Acc: 0.9636, Train F1 Macro: 0.9582, Train F1 Weighted: 0.9638\n",
      "Val Acc: 0.8333, Val F1 Macro: 0.8034, Val F1 Weighted: 0.8328, Val Geometric Mean: 0.8231\n",
      "Test Acc: 0.8333, Test F1 Macro: 0.8034, Test F1 Weighted: 0.8328\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  53%|█████▎    | 160/300 [01:24<01:19,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 160:\n",
      "Train Loss: 0.1269, Train Acc: 0.9714, Train F1 Macro: 0.9708, Train F1 Weighted: 0.9713\n",
      "Val Acc: 0.8333, Val F1 Macro: 0.8178, Val F1 Weighted: 0.8356, Val Geometric Mean: 0.8289\n",
      "Test Acc: 0.8333, Test F1 Macro: 0.8178, Test F1 Weighted: 0.8356\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  57%|█████▋    | 170/300 [01:30<01:13,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 170:\n",
      "Train Loss: 0.1136, Train Acc: 0.9792, Train F1 Macro: 0.9763, Train F1 Weighted: 0.9792\n",
      "Val Acc: 0.8333, Val F1 Macro: 0.8284, Val F1 Weighted: 0.8366, Val Geometric Mean: 0.8328\n",
      "Test Acc: 0.8333, Test F1 Macro: 0.8284, Test F1 Weighted: 0.8366\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  60%|██████    | 180/300 [01:35<01:07,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 180:\n",
      "Train Loss: 0.0722, Train Acc: 0.9870, Train F1 Macro: 0.9841, Train F1 Weighted: 0.9870\n",
      "Val Acc: 0.8125, Val F1 Macro: 0.8026, Val F1 Weighted: 0.8157, Val Geometric Mean: 0.8103\n",
      "Test Acc: 0.8125, Test F1 Macro: 0.8026, Test F1 Weighted: 0.8157\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  63%|██████▎   | 190/300 [01:40<01:01,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 190:\n",
      "Train Loss: 0.0962, Train Acc: 0.9714, Train F1 Macro: 0.9660, Train F1 Weighted: 0.9715\n",
      "Val Acc: 0.8125, Val F1 Macro: 0.7996, Val F1 Weighted: 0.8119, Val Geometric Mean: 0.8080\n",
      "Test Acc: 0.8125, Test F1 Macro: 0.7996, Test F1 Weighted: 0.8119\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  67%|██████▋   | 200/300 [01:46<00:56,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 200:\n",
      "Train Loss: 0.0692, Train Acc: 0.9870, Train F1 Macro: 0.9846, Train F1 Weighted: 0.9870\n",
      "Val Acc: 0.8333, Val F1 Macro: 0.8055, Val F1 Weighted: 0.8331, Val Geometric Mean: 0.8239\n",
      "Test Acc: 0.8333, Test F1 Macro: 0.8055, Test F1 Weighted: 0.8331\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  70%|███████   | 210/300 [01:51<00:50,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 210:\n",
      "Train Loss: 0.0596, Train Acc: 0.9844, Train F1 Macro: 0.9801, Train F1 Weighted: 0.9845\n",
      "Val Acc: 0.8229, Val F1 Macro: 0.8107, Val F1 Weighted: 0.8218, Val Geometric Mean: 0.8185\n",
      "Test Acc: 0.8229, Test F1 Macro: 0.8107, Test F1 Weighted: 0.8218\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  73%|███████▎  | 220/300 [01:56<00:45,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 220:\n",
      "Train Loss: 0.0623, Train Acc: 0.9844, Train F1 Macro: 0.9787, Train F1 Weighted: 0.9843\n",
      "Val Acc: 0.8229, Val F1 Macro: 0.7917, Val F1 Weighted: 0.8234, Val Geometric Mean: 0.8125\n",
      "Test Acc: 0.8229, Test F1 Macro: 0.7917, Test F1 Weighted: 0.8234\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  77%|███████▋  | 230/300 [02:01<00:39,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 230:\n",
      "Train Loss: 0.0655, Train Acc: 0.9818, Train F1 Macro: 0.9807, Train F1 Weighted: 0.9819\n",
      "Val Acc: 0.8229, Val F1 Macro: 0.8014, Val F1 Weighted: 0.8204, Val Geometric Mean: 0.8148\n",
      "Test Acc: 0.8229, Test F1 Macro: 0.8014, Test F1 Weighted: 0.8204\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  80%|████████  | 240/300 [02:07<00:33,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 240:\n",
      "Train Loss: 0.0601, Train Acc: 0.9844, Train F1 Macro: 0.9842, Train F1 Weighted: 0.9844\n",
      "Val Acc: 0.8438, Val F1 Macro: 0.8077, Val F1 Weighted: 0.8426, Val Geometric Mean: 0.8312\n",
      "Test Acc: 0.8438, Test F1 Macro: 0.8077, Test F1 Weighted: 0.8426\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  83%|████████▎ | 250/300 [02:12<00:28,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 250:\n",
      "Train Loss: 0.0751, Train Acc: 0.9792, Train F1 Macro: 0.9780, Train F1 Weighted: 0.9792\n",
      "Val Acc: 0.8542, Val F1 Macro: 0.8428, Val F1 Weighted: 0.8533, Val Geometric Mean: 0.8501\n",
      "Test Acc: 0.8542, Test F1 Macro: 0.8428, Test F1 Weighted: 0.8533\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  87%|████████▋ | 260/300 [02:17<00:22,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 260:\n",
      "Train Loss: 0.0528, Train Acc: 0.9844, Train F1 Macro: 0.9843, Train F1 Weighted: 0.9844\n",
      "Val Acc: 0.8750, Val F1 Macro: 0.8635, Val F1 Weighted: 0.8761, Val Geometric Mean: 0.8715\n",
      "Test Acc: 0.8750, Test F1 Macro: 0.8635, Test F1 Weighted: 0.8761\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  90%|█████████ | 270/300 [02:23<00:17,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 270:\n",
      "Train Loss: 0.3302, Train Acc: 0.9169, Train F1 Macro: 0.9259, Train F1 Weighted: 0.9172\n",
      "Val Acc: 0.8021, Val F1 Macro: 0.7791, Val F1 Weighted: 0.8018, Val Geometric Mean: 0.7943\n",
      "Test Acc: 0.8021, Test F1 Macro: 0.7791, Test F1 Weighted: 0.8018\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  93%|█████████▎| 280/300 [02:28<00:11,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 280:\n",
      "Train Loss: 0.1100, Train Acc: 0.9662, Train F1 Macro: 0.9531, Train F1 Weighted: 0.9665\n",
      "Val Acc: 0.8125, Val F1 Macro: 0.8036, Val F1 Weighted: 0.8125, Val Geometric Mean: 0.8096\n",
      "Test Acc: 0.8125, Test F1 Macro: 0.8036, Test F1 Weighted: 0.8125\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:  97%|█████████▋| 290/300 [02:33<00:05,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 290:\n",
      "Train Loss: 0.0716, Train Acc: 0.9740, Train F1 Macro: 0.9672, Train F1 Weighted: 0.9741\n",
      "Val Acc: 0.8125, Val F1 Macro: 0.8011, Val F1 Weighted: 0.8158, Val Geometric Mean: 0.8098\n",
      "Test Acc: 0.8125, Test F1 Macro: 0.8011, Test F1 Weighted: 0.8158\n",
      "##################################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...: 100%|██████████| 300/300 [02:39<00:00,  1.89it/s]\n",
      "[I 2024-12-31 01:01:33,070] Trial 0 finished with value: 0.6280756137077486 and parameters: {}. Best is trial 0 with value: 0.6280756137077486.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 300:\n",
      "Train Loss: 0.0547, Train Acc: 0.9870, Train F1 Macro: 0.9884, Train F1 Weighted: 0.9870\n",
      "Val Acc: 0.8125, Val F1 Macro: 0.8104, Val F1 Weighted: 0.8139, Val Geometric Mean: 0.8123\n",
      "Test Acc: 0.8125, Test F1 Macro: 0.8104, Test F1 Weighted: 0.8139\n",
      "##################################################\n",
      "New best score: 0.628\n",
      "Best model performance:\n",
      "Accuracy: 0.856 ± 0.023\n",
      "F1 Macro: 0.856 ± 0.019\n",
      "F1 Weighted: 0.856 ± 0.023\n",
      "[{'acc': 0.8865979381443299, 'f1_macro': np.float64(0.8825792628424207), 'f1_weighted': np.float64(0.8862860958900025)}, {'acc': 0.8541666666666666, 'f1_macro': np.float64(0.8576010321683312), 'f1_weighted': np.float64(0.8536538137460786)}, {'acc': 0.84375, 'f1_macro': np.float64(0.8554308957625604), 'f1_weighted': np.float64(0.8434998733535967)}, {'acc': 0.8229166666666666, 'f1_macro': np.float64(0.8230069555912252), 'f1_weighted': np.float64(0.821742910647405)}, {'acc': 0.875, 'f1_macro': np.float64(0.8635034107933377), 'f1_weighted': np.float64(0.8760866508293557)}]\n",
      "Best model performance:\n",
      "Accuracy: 0.856 ± 0.023\n",
      "F1 Macro: 0.856 ± 0.019\n",
      "F1 Weighted: 0.856 ± 0.023\n"
     ]
    }
   ],
   "source": [
    "from src.evals.birgat import BiRGATEvaluator\n",
    "from src.data_managers.bipartite_graph import BipartiteGraphDataManager\n",
    "\n",
    "three_layers = False\n",
    "\n",
    "birgat_eval = BiRGATEvaluator(\n",
    "    data_manager=BipartiteGraphDataManager(\n",
    "        omic_data_loaders=omic_data_loaders,\n",
    "        n_splits=5,\n",
    "        params={\n",
    "            \"diff_exp_thresholds\" : {\n",
    "                \"mrna\": 2.5,\n",
    "                \"mirna\": 2.0,\n",
    "                \"meth\": 2.0,\n",
    "                \"cnv\": 2.0,\n",
    "            },\n",
    "        },\n",
    "        ensembl_feature_names=False,\n",
    "    ),\n",
    "    params={\n",
    "        \"epochs\": 300,\n",
    "        \"log_interval\": 10,\n",
    "        \"hidden_channels\": [128, 64, 64, 16, 16],\n",
    "        \"heads\": 3,\n",
    "        \"dropout\": 0.2,\n",
    "        \"attention_dropout\": 0.0,\n",
    "        \"integrator_type\": \"attention\",\n",
    "        \"three_layers\": three_layers,\n",
    "    },\n",
    "    n_trials=1,\n",
    ")\n",
    "birgat_eval.evaluate()\n",
    "birgat_eval.print_best_results()\n",
    "birgat_eval.save_results(results_file=save_folder, row_name=\"BiRGAT 3L\" if three_layers else \"BiRGAT 2L\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2000 feats\n",
    "Best model performance:\n",
    "Accuracy: 0.856 ± 0.023\n",
    "F1 Macro: 0.856 ± 0.019\n",
    "F1 Weighted: 0.856 ± 0.023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'logs/mds_disease/mrna_mirna_te.csv'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# birgat_eval.save_results(results_file=save_folder, row_name=\"BiRGAT\")\n",
    "save_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "omic_data_loaders = {\n",
    "    \"mrna\": mrna_loader,\n",
    "    \"mirna\": mirna_loader,\n",
    "    \"circrna\": circrna_loader,\n",
    "    # # \"pirna\": pirna_loader,\n",
    "    # \"te\": te_loader,\n",
    "}\n",
    "\n",
    "birgat_eval = BiRGATEvaluator(\n",
    "    data_manager=BipartiteGraphDataManager(\n",
    "        omic_data_loaders=omic_data_loaders,\n",
    "        n_splits=5,\n",
    "        params={\n",
    "            \"diff_exp_thresholds\" : {\n",
    "                \"mrna\": 1.5,\n",
    "                \"mirna\": 1.5,\n",
    "                \"circrna\": 1.7,\n",
    "                # \"te\": 1.8,\n",
    "            },\n",
    "        },\n",
    "    ),\n",
    "    params={\n",
    "        \"epochs\": 250,\n",
    "        \"log_interval\": 50,\n",
    "        \"hidden_channels\": [200, 64, 64, 16, 16],\n",
    "        \"heads\": 4,\n",
    "        \"dropout\": 0.2,\n",
    "        \"attention_dropout\": 0.0,\n",
    "        \"integrator_type\": \"vcdn\",\n",
    "        \"three_layers\": False,\n",
    "    },\n",
    "    n_trials=1,\n",
    ")\n",
    "```\n",
    "\n",
    "Accuracy: 0.960 ± 0.053\n",
    "F1 Macro: 0.940 ± 0.082\n",
    "F1 Weighted: 0.961 ± 0.053"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mrna, mirna, circrna, 2L\n",
    "Accuracy: 0.960 ± 0.033\n",
    "F1 Macro: 0.915 ± 0.073\n",
    "F1 Weighted: 0.956 ± 0.036\n",
    "# mrna, mirna, circrna, 2L no interactions\n",
    "Accuracy: 0.960 ± 0.053\n",
    "F1 Macro: 0.918 ± 0.113\n",
    "F1 Weighted: 0.953 ± 0.064\n",
    "---\n",
    "Accuracy: 0.946 ± 0.027\n",
    "F1 Macro: 0.904 ± 0.048\n",
    "F1 Weighted: 0.944 ± 0.028\n",
    "# mrna, mirna, circrna 3L, interactions, degree ~20 in diff exp graphs, larger degree shows degraded performance\n",
    "# making the avg degree to high shows large jumps on the validation set during training\n",
    "Accuracy: 0.945 ± 0.053\n",
    "F1 Macro: 0.910 ± 0.081\n",
    "F1 Weighted: 0.946 ± 0.048\n",
    "# mrna, mirna, circrna 2L, interactions, 64 cap\n",
    "Accuracy: 0.960 ± 0.053\n",
    "F1 Macro: 0.940 ± 0.082\n",
    "F1 Weighted: 0.961 ± 0.053\n",
    "# mrna, mirna, circrna 3L, interactions, 64 cap\n",
    "Accuracy: 0.891 ± 0.054\n",
    "F1 Macro: 0.801 ± 0.088\n",
    "F1 Weighted: 0.888 ± 0.056\n",
    "# mrna, mirna, circrna 3L\n",
    "Accuracy: 0.920 ± 0.050\n",
    "F1 Macro: 0.829 ± 0.112\n",
    "F1 Weighted: 0.907 ± 0.062\n",
    "# mrna, mirna, 2L\n",
    "Accuracy: 0.960 ± 0.033\n",
    "F1 Macro: 0.915 ± 0.073\n",
    "F1 Weighted: 0.956 ± 0.036\n",
    "# mrna, mirna, 3L\n",
    "Accuracy: 0.947 ± 0.050\n",
    "F1 Macro: 0.897 ± 0.089\n",
    "F1 Weighted: 0.944 ± 0.051"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
